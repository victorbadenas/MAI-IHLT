{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1601723623911",
   "display_name": "Python 3.7.9 64-bit ('IHLT3.7': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Lab.2: Document Structure\n",
    "## Introduction to Human Language Technologies\n",
    "### Victor Badenas Crespo\n",
    "\n",
    "***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Import necessary packages and declare environment valiables."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from pprint import pprint\n",
    "from scipy.stats import pearsonr\n",
    "from nltk.metrics import jaccard_distance\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_FOLDER = Path('./trial')"
   ]
  },
  {
   "source": [
    "First functions for reading and structuring the data are declared, then the input data is read which has multiple lines containing \\[id, sentence1, sentence2\\]. The Gold standard info is also read. Then the inputText is formatted into a dict object with the following format for readability:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"id\": <id_string>,\n",
    "    \"sent1\": <sentence_string>,\n",
    "    \"sent2\": <sentence_string>\n",
    "}\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[{&#39;id&#39;: &#39;id1&#39;,\n  &#39;sent1&#39;: &#39;The bird is bathing in the sink.&#39;,\n  &#39;sent2&#39;: &#39;Birdie is washing itself in the water basin.&#39;},\n {&#39;id&#39;: &#39;id2&#39;,\n  &#39;sent1&#39;: &#39;In May 2010, the troops attempted to invade Kabul.&#39;,\n  &#39;sent2&#39;: &#39;The US army invaded Kabul on May 7th last year, 2010.&#39;},\n {&#39;id&#39;: &#39;id3&#39;,\n  &#39;sent1&#39;: &#39;John said he is considered a witness but not a suspect.&#39;,\n  &#39;sent2&#39;: &#39;&quot;He is not a suspect anymore.&quot; John said.&#39;},\n {&#39;id&#39;: &#39;id4&#39;,\n  &#39;sent1&#39;: &#39;They flew out of the nest in groups.&#39;,\n  &#39;sent2&#39;: &#39;They flew into the nest together.&#39;},\n {&#39;id&#39;: &#39;id5&#39;,\n  &#39;sent1&#39;: &#39;The woman is playing the violin.&#39;,\n  &#39;sent2&#39;: &#39;The young lady enjoys listening to the guitar.&#39;},\n {&#39;id&#39;: &#39;id6&#39;,\n  &#39;sent1&#39;: &#39;John went horse back riding at dawn with a whole group of friends.&#39;,\n  &#39;sent2&#39;: &#39;Sunrise at dawn is a magnificent view to take in if you wake up &#39;\n           &#39;early enough for it.&#39;}]\n"
    }
   ],
   "source": [
    "def readFile(filePath):\n",
    "    \"\"\"\n",
    "    reads and returns a list of lists containing the text split by line \n",
    "    jumps and by tab characters\n",
    "    \"\"\"\n",
    "    with open(filePath, 'r') as fileHandler:\n",
    "        data = fileHandler.readlines()\n",
    "    \n",
    "    # split every line by tabs\n",
    "    data = list(map(lambda x: x.strip().split('\\t'), data))\n",
    "    return data\n",
    "\n",
    "def toDict(line):\n",
    "    \"\"\"\n",
    "    creates a dict with fields id sent1 sent2 from the values in line\n",
    "    \"\"\"\n",
    "    keys = (\"id\", \"sent1\", \"sent2\")\n",
    "    return dict(zip(keys, line))\n",
    "\n",
    "# read file data\n",
    "inputText = readFile(DATA_FOLDER / 'STS.input.txt')\n",
    "gsText = readFile(DATA_FOLDER / 'STS.gs.txt')\n",
    "\n",
    "# convert to previously defined dict structure\n",
    "inputText = list(map(toDict, inputText))\n",
    "pprint(inputText)"
   ]
  },
  {
   "source": [
    "A function is defined that will be responsible of tokenize, convert to set and computing the similarity between both sentences. This function is then applied to the inputText list."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def computeSimilarity(sentencePair):\n",
    "    \"\"\"\n",
    "    function responsible of:\n",
    "    - tokenizing the words in the sentence\n",
    "    - converting to set\n",
    "    - computing the jaccard_distance metric\n",
    "    \"\"\"\n",
    "    sent1 = set(nltk.word_tokenize(sentencePair['sent1'], language='english'))\n",
    "    sent2 = set(nltk.word_tokenize(sentencePair['sent2'], language='english'))\n",
    "    return jaccard_distance(sent1, sent2)"
   ]
  },
  {
   "source": [
    "The previous function is used to compute the distances in inputText. Also the reference distances are extracted from the gold standard text data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDistances = list(map(computeSimilarity, inputText))\n",
    "refDistances = [float(value) for _, value in gsText]"
   ]
  },
  {
   "source": [
    "Both distances are then compared with the pearson correlation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "pearsonr([0.0, 1.0, 2.0, 3.0, 4.0, 5.0], [0.69, 0.74, 0.53, 0.55, 0.77, 0.86]) = 0.3962389776119232\n"
    }
   ],
   "source": [
    "pcorr = pearsonr(refDistances, testDistances)[0]\n",
    "\n",
    "# formatting for purely demonstrative purposes\n",
    "print(f\"pearsonr({refDistances}, {list(map(lambda x:float('%.2f' % x), testDistances))}) = {pcorr}\")"
   ]
  },
  {
   "source": [
    "***\n",
    "\n",
    "## Conclusion\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "***\n",
    "\n",
    "### End of P2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}