{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('IHLT3.7': conda)",
   "display_name": "Python 3.7.9 64-bit ('IHLT3.7': conda)",
   "metadata": {
    "interpreter": {
     "hash": "589da564c3c34ee97637a5e347a7928039a22cef64d507784db9da12a80e8881"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Lab.2: Document Structure\n",
    "## Introduction to Human Language Technologies\n",
    "### Victor Badenas Crespo\n",
    "\n",
    "***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Import necessary packages and declare environment valiables."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\victo\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from pprint import pprint\n",
    "from scipy.stats import pearsonr\n",
    "from nltk.metrics import jaccard_distance\n",
    "from pathlib import Path\n",
    "nltk.download('punkt')\n",
    "\n",
    "DATA_FOLDER = Path('./trial')"
   ]
  },
  {
   "source": [
    "First functions for reading and structuring the data are declared, then the input data is read which has multiple lines containing \\[id, sentence1, sentence2\\]. The Gold standard info is also read. Then the inputText is formatted into a dict object with the following format for readability:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"id\": <id_string>,\n",
    "    \"sent1\": <sentence_string>,\n",
    "    \"sent2\": <sentence_string>\n",
    "}\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[{'id': 'id1',\n  'sent1': 'The bird is bathing in the sink.',\n  'sent2': 'Birdie is washing itself in the water basin.'},\n {'id': 'id2',\n  'sent1': 'In May 2010, the troops attempted to invade Kabul.',\n  'sent2': 'The US army invaded Kabul on May 7th last year, 2010.'},\n {'id': 'id3',\n  'sent1': 'John said he is considered a witness but not a suspect.',\n  'sent2': '\"He is not a suspect anymore.\" John said.'},\n {'id': 'id4',\n  'sent1': 'They flew out of the nest in groups.',\n  'sent2': 'They flew into the nest together.'},\n {'id': 'id5',\n  'sent1': 'The woman is playing the violin.',\n  'sent2': 'The young lady enjoys listening to the guitar.'},\n {'id': 'id6',\n  'sent1': 'John went horse back riding at dawn with a whole group of friends.',\n  'sent2': 'Sunrise at dawn is a magnificent view to take in if you wake up '\n           'early enough for it.'}]\n"
     ]
    }
   ],
   "source": [
    "def readFile(filePath):\n",
    "    \"\"\"\n",
    "    reads and returns a list of lists containing the text split by line \n",
    "    jumps and by tab characters\n",
    "    \"\"\"\n",
    "    with open(filePath, 'r') as fileHandler:\n",
    "        data = fileHandler.readlines()\n",
    "    \n",
    "    # split every line by tabs\n",
    "    data = list(map(lambda x: x.strip().split('\\t'), data))\n",
    "    return data\n",
    "\n",
    "def toDict(line):\n",
    "    \"\"\"\n",
    "    creates a dict with fields id sent1 sent2 from the values in line\n",
    "    \"\"\"\n",
    "    keys = (\"id\", \"sent1\", \"sent2\")\n",
    "    return dict(zip(keys, line))\n",
    "\n",
    "# read file data\n",
    "inputText = readFile(DATA_FOLDER / 'STS.input.txt')\n",
    "gsText = readFile(DATA_FOLDER / 'STS.gs.txt')\n",
    "\n",
    "# convert to previously defined dict structure\n",
    "inputText = list(map(toDict, inputText))\n",
    "pprint(inputText)"
   ]
  },
  {
   "source": [
    "A function is defined that will be responsible of tokenize, convert to set and computing the similarity between both sentences. This function is then applied to the inputText list."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def computeSimilarity(sentencePair):\n",
    "    \"\"\"\n",
    "    function responsible of:\n",
    "    - tokenizing the words in the sentence\n",
    "    - converting to set\n",
    "    - computing the jaccard_distance metric\n",
    "    \"\"\"\n",
    "    sent1 = set(nltk.word_tokenize(sentencePair['sent1'], language='english'))\n",
    "    sent2 = set(nltk.word_tokenize(sentencePair['sent2'], language='english'))\n",
    "    return jaccard_distance(sent1, sent2)"
   ]
  },
  {
   "source": [
    "The previous function is used to compute the distances in inputText. Also the reference distances are extracted from the gold standard text data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDistances = list(map(computeSimilarity, inputText))\n",
    "refDistances = [float(value)/(len(gsText)-1) for _, value in gsText]"
   ]
  },
  {
   "source": [
    "Both distances are then compared with the pearson correlation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pearsonr([0.0, 0.2, 0.4, 0.6, 0.8, 1.0], [0.69, 0.74, 0.53, 0.55, 0.77, 0.86]) = 0.3962389776119232\n"
     ]
    }
   ],
   "source": [
    "pcorr = pearsonr(refDistances, testDistances)[0]\n",
    "\n",
    "# formatting for purely demonstrative purposes\n",
    "print(f\"pearsonr({list(map(lambda x:float('%.2f' % x), refDistances))}, {list(map(lambda x:float('%.2f' % x), testDistances))}) = {pcorr}\")"
   ]
  },
  {
   "source": [
    "***\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The gold standard has a measure of distance between the sentences in each sentence pair identified by the id. The jaccard_distance, as measured by the following equation, will measure the similarity between the sets of words that it is given.\n",
    "\n",
    "\\begin{equation}\n",
    "    S_{jaccard}(X,Y)=\\frac{\\vert X \\cap Y\\vert}{\\vert X \\cup Y\\vert}\n",
    "\\end{equation}\n",
    "\n",
    "However, the words in a sentence alone are not representative of the semantical meaning of the whole sentence. Because of that the correlation between the gold standard and the jaccard_distance metric is only a 0.4.\n",
    "\n",
    "For instance in the first pair of sentences (which are the most similar and the distance should be 0) create the following results:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\"The bird is bathing in the sink.\", \"Birdie is washing itself in the water basin.\"\n"
     ]
    }
   ],
   "source": [
    "sentenceTestPair = inputText[0]\n",
    "sent1 = sentenceTestPair['sent1']\n",
    "sent2 = sentenceTestPair['sent2']\n",
    "print(f\"\\\"{sent1}\\\", \\\"{sent2}\\\"\")"
   ]
  },
  {
   "source": [
    "If we think on the context or overall meaning of the sentences, it is obvious that the sentences have the same meaning. However both of them are phrased different, using word derivatives such as ```bird``` and ```Birdie```. This difference will not compute positively to the distance computation. \n",
    "\n",
    "If we look at a more step by step implementation of the jaccard_distance, we can compute and then analyse the intersection and union operands that conform the similarity metric:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['.', 'The', 'bathing', 'bird', 'in', 'is', 'sink', 'the']\n['.', 'Birdie', 'basin', 'in', 'is', 'itself', 'the', 'washing', 'water']\n"
     ]
    }
   ],
   "source": [
    "sent1 = set(nltk.word_tokenize(sent1, language='english'))\n",
    "sent2 = set(nltk.word_tokenize(sent2, language='english'))\n",
    "print(sorted(sent1))\n",
    "print(sorted(sent2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'is', 'in', 'the', '.'}\n{'sink', 'washing', 'water', 'bathing', 'in', 'The', 'Birdie', 'bird', 'the', 'basin', 'itself', 'is', '.'}\n"
     ]
    }
   ],
   "source": [
    "intersecion = sent1.intersection(sent2)\n",
    "union = sent1.union(sent2)\n",
    "print(intersecion)\n",
    "print(union)"
   ]
  },
  {
   "source": [
    "From that computation, the only words that are present in both sentences are {'is', 'the', '.', 'in'} which are pretty common words and have no actual semantical information in them. Because of the intersecion of words being so small, the similarity metric (as it is shown in the next cell) will be so small and as a consequence, the distance bigger."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "len(intersecion): 4\nlen(union): 13\ncomputed jaccard similarity: 0.3076923076923077\ncomputed jaccard_distance: 0.6923076923076923\n"
     ]
    }
   ],
   "source": [
    "print(\"len(intersecion):\", len(intersecion))\n",
    "print(\"len(union):\", len(union))\n",
    "print(\"computed jaccard similarity:\", len(intersecion)/len(union))\n",
    "print(\"computed jaccard_distance:\", 1-(len(intersecion)/len(union)))"
   ]
  },
  {
   "source": [
    "The computed jaccard distance is the same as it is returned by the nltk package's function. So, because the words similar between sentences are not as similar as the meaning may suggest, we can conclude that the jaccard distance is not a good enough metric to correctly represent the distance between sentences. Maybe some preprocessing to filter stopwords and then translate derivated words to the baseword would be beneficial before actually computing the distance."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "***\n",
    "\n",
    "## Optional: extract the correlation from all gold standards from test-gold\n",
    "\n",
    "in this case, the gold standard is the similarity metric and it is converted using:\n",
    "\n",
    "$$D_{jaccard}=1-S_{jaccard}$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "------------------------------------------------------------\n",
      "correlation for file test-gold\\STS.input.MSRpar.txt: 0.51\n",
      "------------------------------------------------------------\n",
      "correlation for file test-gold\\STS.input.MSRvid.txt: 0.36\n",
      "------------------------------------------------------------\n",
      "correlation for file test-gold\\STS.input.SMTeuroparl.txt: 0.45\n",
      "------------------------------------------------------------\n",
      "correlation for file test-gold\\STS.input.surprise.OnWN.txt: 0.64\n",
      "------------------------------------------------------------\n",
      "correlation for file test-gold\\STS.input.surprise.SMTnews.txt: 0.36\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "TEST_PATH = Path('./test-gold')\n",
    "\n",
    "inputTestPaths = sorted(TEST_PATH.glob(\"STS.input.*.txt\"))\n",
    "\n",
    "for inputTestPath in inputTestPaths:\n",
    "    print('-'*60)\n",
    "    gsTestPath = inputTestPath.parent / (inputTestPath.stem.replace('input', 'gs') + '.txt')\n",
    "\n",
    "    inputText = readFile(inputTestPath)\n",
    "    gsText = readFile(gsTestPath)\n",
    "\n",
    "    gsDistances = [1-float(value) for line in gsText for value in line]\n",
    "\n",
    "    distanceScores = list()\n",
    "    for sentencePair in inputText:\n",
    "        sentencePair[0] = set(nltk.word_tokenize(sentencePair[0], language='english'))\n",
    "        sentencePair[1] = set(nltk.word_tokenize(sentencePair[1], language='english'))\n",
    "        distanceScores.append(jaccard_distance(*sentencePair))\n",
    "\n",
    "    correlation = pearsonr(distanceScores, gsDistances)[0]\n",
    "    print(f\"correlation for file {inputTestPath}: {correlation:.2f}\")\n",
    "print('-'*60)\n"
   ]
  },
  {
   "source": [
    "***\n",
    "\n",
    "### End of P2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}