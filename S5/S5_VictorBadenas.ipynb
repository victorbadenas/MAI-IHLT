{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('IHLT3.7': conda)",
   "display_name": "Python 3.7.9 64-bit ('IHLT3.7': conda)",
   "metadata": {
    "interpreter": {
     "hash": "d95a5ba215b5c0d3c5562e0f5b2730844d9eca1086482e66ee8573214ced8df7"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Lab.4: Part of Speech\n",
    "## Introduction to Human Language Technologies\n",
    "### Victor Badenas Crespo\n",
    "\n",
    "***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Statement:\n",
    "\n",
    "Given the following (lemma, category) pairs:\n",
    "```python\n",
    "(’the’,’DT’), (’man’,’NN’), (’swim’,’VB’), (’with’, ’PR’), (’a’, ’DT’),\n",
    "(’girl’,’NN’), (’and’, ’CC’), (’a’, ’DT’), (’boy’, ’NN’), (’whilst’, ’PR’),\n",
    "(’the’, ’DT’), (’woman’, ’NN’), (’walk’, ’VB’)\n",
    "```\n",
    "\n",
    "- For each pair, when possible, print their most frequent WordNet synset, their corresponding least common subsumer (LCS) and their similarity value, using the following functions:\n",
    "\n",
    "    - Path Similarity\n",
    "\n",
    "    - Leacock-Chodorow Similarity\n",
    "\n",
    "    - Wu-Palmer Similarity\n",
    "\n",
    "    - Lin Similarity\n",
    "\n",
    "- Normalize similarity values when necessary. What similarity seems better?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "*** \n",
    "\n",
    "## Solution\n",
    "\n",
    "Import necessary packages and declare environment valiables."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('man', 'NN'), ('swim', 'VB'), ('girl', 'NN'), ('boy', 'NN'), ('woman', 'NN'), ('walk', 'VB')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "DATA = [\n",
    "    ('the','DT'), ('man','NN'), ('swim','VB'), ('with', 'PR'), ('a', 'DT'),\n",
    "    ('girl','NN'), ('and', 'CC'), ('a', 'DT'), ('boy', 'NN'), ('whilst', 'PR'),\n",
    "    ('the', 'DT'), ('woman', 'NN'), ('walk', 'VB')\n",
    "]\n",
    "\n",
    "print(list(filter(lambda x: x[1].lower()[0] in ('v', 'n'), DATA)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "synsets = list()\n",
    "for word, posTag in DATA:\n",
    "    posTag = posTag.lower()[0]\n",
    "    if posTag in ('n', 'v'):\n",
    "        synset = wn.synsets(word, posTag)[0]\n",
    "        synsets.append(synset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1.                nan 0.63157895 0.66666667 0.66666667        nan]\n [0.18181818 1.         0.16666667 0.18181818 0.18181818 0.33333333]\n [0.63157895        nan 1.         0.63157895 0.63157895        nan]\n [0.66666667        nan 0.63157895 1.         0.66666667        nan]\n [0.66666667        nan 0.94736842 0.66666667 1.                nan]\n [0.18181818 0.33333333 0.16666667 0.18181818 0.18181818 1.        ]]\n[1 5 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "distances = np.zeros((len(synsets), len(synsets)))\n",
    "for ix in range(0, len(distances)):\n",
    "    for iy in range(0, len(distances)):\n",
    "        distance = synsets[ix].wup_similarity(synsets[iy])\n",
    "        distances[ix,iy] = distance\n",
    "print(distances)\n",
    "lcsIndexes = np.nanargmin(distances, axis=0)\n",
    "print(lcsIndexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "WordNetError",
     "evalue": "Computing the lch similarity requires Synset('man.n.01') and Synset('swim.v.01') to have the same part of speech.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWordNetError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-ece43c98db46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlcssynset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msynsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlcsIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mPathSimilarities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msynset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlcssynset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mLCSimilaities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msynset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlch_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlcssynset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mWuPalmerSimilarities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msynset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwup_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlcssynset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mLinSimilarities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msynset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlcssynset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/IHLT3.7/lib/python3.7/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36mlch_similarity\u001b[0;34m(self, other, verbose, simulate_root)\u001b[0m\n\u001b[1;32m    856\u001b[0m             raise WordNetError(\n\u001b[1;32m    857\u001b[0m                 \u001b[0;34m\"Computing the lch similarity requires \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m                 \u001b[0;34m\"%s and %s to have the same part of speech.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    859\u001b[0m             )\n\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWordNetError\u001b[0m: Computing the lch similarity requires Synset('man.n.01') and Synset('swim.v.01') to have the same part of speech."
     ]
    }
   ],
   "source": [
    "PathSimilarities = list()\n",
    "LCSimilaities = list()\n",
    "WuPalmerSimilarities = list()\n",
    "LinSimilarities = list()\n",
    "for synset, lcsIndex in zip(synsets, lcsIndexes):\n",
    "    lcssynset = synsets[lcsIndex]\n",
    "    PathSimilarities.append(synset.path_similarity(lcssynset))\n",
    "    LCSimilaities.append(synset.lch_similarity(lcssynset))\n",
    "    WuPalmerSimilarities.append(synset.wup_similarity(lcssynset))\n",
    "    LinSimilarities.append(synset.lin_similarity(lcssynset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PathSimilarities)\n",
    "print(LCSimilaities)\n",
    "print(WuPalmerSimilarities)\n",
    "print(LinSimilarities)"
   ]
  },
  {
   "source": [
    "***\n",
    "\n",
    "## Conclusions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "***\n",
    "\n",
    "### End of P4"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}