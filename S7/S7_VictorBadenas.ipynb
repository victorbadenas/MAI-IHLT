{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37964bitihlt37conda7204be5f521f4785b21789281fd931be",
   "display_name": "Python 3.7.9 64-bit ('IHLT3.7': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Lab 7: Word Sequences\n",
    "## Introduction to Human Language Technologies\n",
    "### Victor Badenas Crespo\n",
    "\n",
    "***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Statement:\n",
    "\n",
    "- Read all pairs of sentences of the trial set within the evaluation framework of the project.\n",
    "- Compute their similarities by considering the following approach:\n",
    "    - words plus NEs and Jaccard coefficient ex: word_and_NEs=\\['John Smith', 'is', 'working'\\]\n",
    "- Show the results.\n",
    "- Do you think it could be relevant to use NEs to compute the similarity between two sentences? Justify the answer.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "***\n",
    "\n",
    "## Solution"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n[nltk_data]     /home/victorbadenas/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package words to\n[nltk_data]     /home/victorbadenas/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     /home/victorbadenas/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /home/victorbadenas/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package maxent_ne_chunker to\n[nltk_data]     /home/victorbadenas/nltk_data...\n[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n[nltk_data] Downloading package conll2000 to\n[nltk_data]     /home/victorbadenas/nltk_data...\n[nltk_data]   Package conll2000 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# core imports\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "# scipy imports\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# nltk imports\n",
    "import nltk\n",
    "from nltk.metrics import jaccard_distance\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.wsd import lesk\n",
    "\n",
    "# nltk downloads\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('conll2000')\n",
    "\n",
    "# constants definition\n",
    "DATA_FOLDER = Path('./test-gold')"
   ]
  },
  {
   "source": [
    "First functions for reading and structuring the data are declared, then the input data is read which has multiple lines containing \\[id, sentence1, sentence2\\]. The Gold standard info is also read. Then the inputText is formatted into a dict object with the following format for readability:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"id\": <id_string>,\n",
    "    \"sent1\": <sentence_string>,\n",
    "    \"sent2\": <sentence_string>\n",
    "}\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'sent1': '\"It\\'s a huge black eye,\" said publisher Arthur Ochs Sulzberger '\n          'Jr., whose family has controlled the paper since 1896.',\n 'sent2': '\"It\\'s a huge black eye,\" Arthur Sulzberger, the newspaper\\'s '\n          'publisher, said of the scandal.'}\n"
     ]
    }
   ],
   "source": [
    "def readFile(filePath):\n",
    "    \"\"\"\n",
    "    reads and returns a list of lists containing the text split by line \n",
    "    jumps and by tab characters\n",
    "    \"\"\"\n",
    "    with open(filePath, 'r') as fileHandler:\n",
    "        data = fileHandler.readlines()\n",
    "    \n",
    "    # split every line by tabs\n",
    "    data = list(map(lambda x: x.strip().split('\\t'), data))\n",
    "    return data\n",
    "\n",
    "def toDict(line):\n",
    "    \"\"\"\n",
    "    creates a dict with fields id sent1 sent2 from the values in line\n",
    "    \"\"\"\n",
    "    keys = (\"sent1\", \"sent2\")\n",
    "    return dict(zip(keys, line))\n",
    "\n",
    "# read file data\n",
    "txtPaths = list(DATA_FOLDER.glob('STS.input.*.txt'))\n",
    "gsPaths = list(DATA_FOLDER.glob('STS.gs.[!ALL]*.txt'))\n",
    "\n",
    "inputText = []\n",
    "for path in txtPaths:\n",
    "    inputText += readFile(path)\n",
    "\n",
    "gsText = []\n",
    "for path in gsPaths:\n",
    "    gsText += readFile(path)\n",
    "\n",
    "# convert to previously defined dict structure\n",
    "inputText = list(map(toDict, inputText))\n",
    "pprint(inputText[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processCoNLL(conll):\n",
    "    words = []\n",
    "    for line in conll.split('\\n'):\n",
    "        token, _, NEtag = line.split()\n",
    "        if NEtag.startswith(\"B-\"):\n",
    "            words.append(NEtag.replace(\"B-\", \"\"))\n",
    "        elif NEtag.startswith(\"I-\"):\n",
    "            pass\n",
    "        else:\n",
    "            words.append(token)\n",
    "    return set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in inputText:\n",
    "    sent1, sent2 = sentence[\"sent1\"], sentence[\"sent2\"]\n",
    "    sent1 = nltk.word_tokenize(sent1)\n",
    "    sent2 = nltk.word_tokenize(sent2)\n",
    "    t_POS_sent1 = nltk.pos_tag(sent1)\n",
    "    t_POS_sent2 = nltk.pos_tag(sent2)\n",
    "    ne_chunk1 = nltk.ne_chunk(t_POS_sent1)\n",
    "    ne_chunk2 = nltk.ne_chunk(t_POS_sent2)\n",
    "    conll1 = nltk.chunk.tree2conllstr(ne_chunk1)\n",
    "    conll2 = nltk.chunk.tree2conllstr(ne_chunk2)\n",
    "    sentence[\"conll1\"] = processCoNLL(conll1)\n",
    "    sentence[\"conll2\"] = processCoNLL(conll2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'conll1': {\"''\",\n            \"'s\",\n            ',',\n            '.',\n            '1896',\n            'It',\n            'PERSON',\n            '``',\n            'a',\n            'black',\n            'controlled',\n            'eye',\n            'family',\n            'has',\n            'huge',\n            'paper',\n            'publisher',\n            'said',\n            'since',\n            'the',\n            'whose'},\n 'conll2': {\"''\",\n            \"'s\",\n            ',',\n            '.',\n            'It',\n            'PERSON',\n            '``',\n            'a',\n            'black',\n            'eye',\n            'huge',\n            'newspaper',\n            'of',\n            'publisher',\n            'said',\n            'scandal',\n            'the'},\n 'sent1': '\"It\\'s a huge black eye,\" said publisher Arthur Ochs Sulzberger '\n          'Jr., whose family has controlled the paper since 1896.',\n 'sent2': '\"It\\'s a huge black eye,\" Arthur Sulzberger, the newspaper\\'s '\n          'publisher, said of the scandal.'}\n"
     ]
    }
   ],
   "source": [
    "pprint(inputText[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSimilarity(sentenceDict):\n",
    "    context1 = set(sentenceDict[\"conll1\"])\n",
    "    context2 = set(sentenceDict[\"conll2\"])\n",
    "    return 1-jaccard_distance(context1, context2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ".75, 4.5, 5.0, 5.0, 4.5, 3.0, 3.4, 4.5, 3.8, 2.83, 4.75, 4.75, 4.5, 5.0, 4.25, 5.0, 3.6, 0.5, 2.2, 5.0, 5.0, 4.67, 4.75, 4.25, 5.0, 5.0, 4.75, 4.5, 4.75, 4.5, 2.5, 1.75, 2.75, 2.25, 5.0, 3.75, 4.0, 4.0, 4.75, 5.0, 5.0, 4.5, 4.25, 5.0, 5.0, 4.75, 4.5, 5.0, 5.0, 4.8, 5.0, 3.4, 5.0, 5.0, 5.0, 5.0, 3.75, 5.0, 4.6, 4.75, 4.8, 4.0, 3.75, 4.71, 5.0, 4.6, 3.2, 4.5, 4.0, 3.0, 4.6, 2.25, 4.0, 4.4, 2.83, 2.75, 4.75, 5.0, 5.0, 5.0, 3.75, 4.25, 4.75, 5.0, 4.5, 4.4, 5.0, 4.75, 4.6, 3.75, 4.75, 4.75, 5.0, 2.25, 4.5, 4.75, 4.75, 4.8, 4.25, 2.5, 5.0, 5.0, 5.0, 3.5, 4.25, 4.25, 4.0, 0.25, 4.25, 5.0, 3.75, 3.75, 5.0, 2.75, 4.75, 1.75, 4.5, 3.5, 4.5, 4.75, 5.0, 5.0, 4.75, 4.0, 5.0, 5.0, 4.5, 5.0, 4.75, 5.0, 5.0, 4.75, 4.25, 4.25, 4.75, 5.0, 4.5, 3.5, 2.75, 3.75, 3.5, 5.0, 4.5, 4.75, 5.0, 4.4, 4.25, 4.5, 4.75, 4.25, 3.8, 4.5, 4.5, 4.25, 5.0, 4.25, 4.5, 4.5, 4.75, 4.75, 4.75, 2.5, 4.5, 3.5, 4.4, 4.25, 3.75, 4.75, 4.75, 4.75, 4.25, 5.0, 2.83, 5.0, 5.0, 4.75, 4.75, 3.5, 5.0, 4.75, 4.0, 5.0, 4.25, 4.8, 5.0, 4.67, 5.0, 4.25, 4.0, 5.0, 0.25, 5.0, 3.6, 4.25, 4.75, 4.25, 5.0, 5.0, 5.0, 4.71, 3.75, 4.6, 4.5, 4.75, 2.0, 5.0, 3.75, 5.0, 5.0, 4.75, 5.0, 4.75, 4.0, 5.0, 4.71, 3.25, 4.75, 4.0, 3.0, 4.5, 4.5, 5.0, 5.0, 4.75, 3.75, 4.0, 4.5, 4.0, 4.75, 4.25, 4.75, 4.0, 2.75, 5.0, 2.25, 3.75, 5.0, 3.5, 4.75, 4.71, 3.5, 3.25, 5.0, 5.0, 5.0, 3.75, 4.0, 5.0, 4.25, 3.75, 4.0, 3.5, 4.8, 4.0, 5.0, 4.25, 5.0, 4.8, 4.75, 4.5, 4.0, 5.0, 4.6, 4.75, 5.0, 5.0, 4.5, 4.5, 5.0, 3.5, 4.75, 3.5, 4.5, 4.25, 5.0, 2.5, 4.25, 4.25, 4.4, 4.75, 4.8, 3.75, 5.0, 4.75, 4.75, 4.2, 5.0, 4.6, 4.75, 4.75, 4.5, 3.25, 4.4, 4.5, 4.5, 4.0, 4.33, 5.0, 5.0, 5.0, 4.75, 4.75, 5.0, 4.0, 4.75, 4.5, 4.5, 4.25, 4.75, 5.0, 4.75, 4.25, 3.6, 3.6, 2.75, 5.0, 3.75, 4.2, 3.5, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.75, 4.25, 5.0, 4.5, 3.25, 5.0, 4.5, 4.5, 4.8, 5.0, 4.5, 5.0, 4.75, 5.0, 4.75, 5.0, 4.0, 4.75, 5.0, 3.75, 4.75, 2.25, 5.0, 4.5, 4.5, 4.67, 5.0, 4.25, 4.67, 5.0, 4.75, 5.0, 4.0, 4.5, 2.25, 3.75, 5.0, 3.0, 4.75, 4.75, 4.5, 1.0, 3.25, 3.5], [0.28, 0.25, 0.58, 0.62, 0.23, 0.43, 0.47, 0.54, 0.58, 0.55, 0.23, 0.41, 0.5, 0.38, 0.21, 0.43, 0.43, 0.52, 0.47, 0.35, 0.32, 0.42, 0.73, 0.62, 0.44, 0.57, 0.68, 0.29, 0.35, 0.42, 0.68, 0.42, 0.45, 0.43, 0.48, 0.67, 0.54, 0.33, 0.55, 0.48, 0.54, 0.81, 0.45, 0.46, 0.66, 0.3, 0.3, 0.41, 0.4, 0.73, 0.55, 0.58, 0.72, 0.41, 0.6, 0.27, 0.48, 0.43, 0.28, 0.24, 0.67, 0.41, 0.36, 0.59, 0.63, 0.38, 0.64, 0.37, 0.33, 0.46, 0.66, 0.38, 0.2, 0.4, 0.45, 0.32, 0.33, 0.54, 0.44, 0.66, 0.47, 0.71, 0.83, 0.34, 0.75, 0.38, 0.48, 0.6, 0.32, 0.44, 0.38, 0.62, 0.38, 0.2, 0.36, 0.65, 0.39, 0.61, 0.26, 0.24, 0.38, 0.36, 0.55, 0.45, 0.54, 0.58, 0.55, 0.35, 0.36, 0.36, 0.28, 0.46, 0.28, 0.53, 0.55, 0.21, 0.47, 0.32, 0.19, 0.71, 0.33, 0.43, 0.42, 0.61, 0.56, 0.56, 0.77, 0.53, 0.68, 0.33, 0.22, 0.39, 0.23, 0.41, 0.21, 0.37, 0.59, 0.45, 0.4, 0.52, 0.5, 0.28, 0.48, 0.6, 0.44, 0.58, 0.5, 0.62, 0.33, 0.55, 0.54, 0.65, 0.38, 0.5, 0.24, 0.25, 0.59, 0.6, 0.58, 0.35, 0.76, 0.32, 0.63, 0.62, 0.43, 0.42, 0.68, 0.47, 0.52, 0.5, 0.56, 0.56, 0.65, 0.42, 0.38, 0.28, 0.35, 0.54, 0.4, 0.28, 0.67, 0.38, 0.43, 0.4, 0.25, 0.2, 0.52, 0.39, 0.5, 0.5, 0.56, 0.62, 0.48, 0.35, 0.37, 0.42, 0.56, 0.74, 0.24, 0.17, 0.67, 0.53, 0.29, 0.48, 0.52, 0.52, 0.46, 0.29, 0.52, 0.29, 0.55, 0.42, 0.44, 0.28, 0.33, 0.52, 0.33, 0.33, 0.43, 0.28, 0.3, 0.35, 0.62, 0.55, 0.5, 0.35, 0.3, 0.55, 0.52, 0.5, 0.5, 0.36, 0.56, 0.5, 0.26, 0.68, 0.32, 0.37, 0.6, 0.35, 0.53, 0.4, 0.42, 0.29, 0.5, 0.33, 0.27, 0.47, 0.5, 0.45, 0.3, 0.46, 0.35, 0.54, 0.52, 0.41, 0.37, 0.28, 0.29, 0.75, 0.28, 0.5, 0.38, 0.36, 0.58, 0.66, 0.69, 0.26, 0.61, 0.32, 0.23, 0.52, 0.71, 0.55, 0.32, 0.58, 0.45, 0.6, 0.35, 0.5, 0.44, 0.41, 0.42, 0.32, 0.38, 0.4, 0.67, 0.4, 0.47, 0.61, 0.26, 0.47, 0.57, 0.48, 0.71, 0.56, 0.56, 0.53, 0.54, 0.67, 0.77, 0.24, 0.43, 0.5, 0.36, 0.41, 0.47, 0.42, 0.63, 0.5, 0.33, 0.5, 0.36, 0.6, 0.4, 0.45, 0.32, 0.44, 0.33, 0.44, 0.4, 0.38, 0.7, 0.33, 0.37, 0.41, 0.59, 0.41, 0.53, 0.71, 0.5, 0.52, 0.33, 0.63, 0.23, 0.52, 0.6, 0.82, 0.82, 0.29, 0.26, 0.38, 0.45, 0.57, 0.43, 0.4, 0.71, 0.56, 0.29, 0.38, 0.59, 0.33, 0.24, 0.55, 0.48, 0.4, 0.47, 0.36, 0.3, 0.35, 0.37, 0.3, 0.22, 0.37, 0.67, 0.57, 0.63, 0.24, 0.23, 0.35, 0.3, 0.56, 0.43, 0.23, 0.48, 0.45, 0.35, 0.41, 0.52, 0.52, 0.3, 0.29, 0.53, 0.53, 0.33, 0.39, 0.54, 0.54, 0.36, 0.5, 0.48, 0.24, 0.46, 0.48, 0.4, 0.52, 0.38, 0.39, 0.39, 0.42, 0.21, 0.38, 0.37, 0.38, 0.56, 0.5, 0.43, 0.56, 0.35, 0.6, 0.39, 0.24, 0.58, 0.33, 0.43, 0.35, 0.43, 0.4, 0.43, 0.62, 0.32, 0.3, 0.36, 0.4, 0.52, 0.5, 0.59, 0.39, 0.5, 0.53, 0.76, 0.32, 0.4, 0.5, 0.68, 0.29, 0.27, 0.67, 0.33, 0.47, 0.58, 0.56, 0.42, 0.61, 0.24, 0.3, 0.4, 0.61, 0.33, 0.38, 0.57, 0.62, 0.33, 0.56, 0.45, 0.29, 0.35, 0.41, 0.43, 0.55, 0.72, 0.64, 0.43, 0.29, 0.35, 0.52, 0.35, 0.41, 0.59, 0.4, 0.4, 0.57, 0.55, 0.42, 0.74, 0.83, 0.5, 0.27, 0.55, 0.29, 0.25, 0.38, 0.5, 0.53, 0.73, 0.76, 0.43, 0.67, 0.56, 0.54, 0.54, 0.42, 0.5, 0.43, 0.38, 0.44, 0.56, 0.27, 0.35, 0.22, 0.23, 0.54, 0.27, 0.33, 0.36, 0.73, 0.52, 0.55, 0.41, 0.46, 0.41, 0.24, 0.5, 0.66, 0.26, 0.4, 0.5, 0.27, 0.39, 0.45, 0.67, 0.8, 0.61, 0.42, 0.52, 0.33, 0.33, 0.52, 0.46, 0.5, 0.33, 0.39, 0.37, 0.62, 0.35, 0.39, 0.87, 0.58, 0.29, 0.85, 0.45, 0.27, 0.92, 0.35, 0.57, 0.54, 0.38, 0.42, 0.45, 0.61, 0.38, 0.55, 0.6, 0.3, 0.38, 0.36, 0.25, 0.22, 0.38, 0.41, 0.57, 0.55, 0.76, 0.12, 0.39, 0.38, 0.29, 0.39, 0.7, 0.45, 0.47, 0.45, 0.36, 0.33, 0.32, 0.43, 0.53, 0.66, 0.26, 0.25, 0.5, 0.46, 0.39, 0.64, 0.62, 0.66, 0.36, 0.39, 0.24, 0.69, 0.58, 0.25, 0.62, 0.82, 0.67, 0.58, 0.44, 0.49, 0.46, 0.33, 0.38, 0.26, 0.74, 0.56, 0.5, 0.4, 0.52, 0.63, 0.58, 0.48, 0.6, 0.39, 0.32, 0.55, 0.66, 0.4, 0.55, 0.31, 0.48, 0.66, 0.45, 0.37, 0.55, 0.38, 0.36, 0.5, 0.55, 0.35, 0.68, 0.6, 0.36, 0.28, 0.54, 0.5, 0.4, 0.48, 0.35, 0.55, 0.35, 0.44, 0.37, 0.24, 0.57, 0.67, 0.47, 0.33, 0.14, 0.62, 0.36, 0.6, 0.32, 0.52, 0.38, 0.71, 0.69, 0.33, 0.23, 0.12, 0.35, 0.35, 0.54, 0.25, 0.41, 0.19, 0.31, 0.7, 0.36, 0.19, 0.73, 0.32, 0.27, 0.71, 0.44, 0.5, 0.28, 0.44, 0.22, 0.27, 0.46, 0.63, 0.58, 0.42, 0.3, 0.26, 0.73, 0.52, 0.41, 0.5, 0.5, 0.71, 0.29, 0.42, 0.43, 0.56, 0.71, 0.8, 0.39, 0.4, 0.61, 0.52, 0.39, 0.26, 0.26, 0.72, 0.5, 0.29, 0.41, 0.32, 0.26, 0.41, 0.59, 0.59, 0.32, 0.67, 0.44, 0.44, 0.57, 0.5, 0.65, 0.41, 0.65, 0.5, 0.68, 0.28, 0.25, 0.41, 0.69, 0.68, 0.42, 0.24, 0.25, 0.43, 0.44, 0.37, 0.33, 0.38, 0.38, 0.41, 0.47, 0.18, 0.37, 0.5, 0.42, 0.32, 0.64, 0.42, 0.4, 0.32, 0.6, 0.29, 0.8, 0.62, 0.88, 0.73, 0.88, 0.62, 0.71, 0.62, 0.56, 0.88, 0.44, 0.67, 0.67, 0.75, 0.54, 0.6, 0.67, 0.8, 0.77, 0.88, 0.7, 0.7, 0.53, 0.56, 0.75, 0.64, 0.67, 0.75, 0.7, 0.67, 0.6, 0.75, 0.67, 0.62, 0.71, 0.62, 0.62, 0.67, 0.56, 0.75, 0.56, 0.56, 0.6, 0.67, 0.64, 0.5, 0.88, 0.67, 0.56, 0.56, 0.54, 0.5, 0.56, 0.8, 0.67, 0.62, 0.62, 0.56, 0.57, 0.71, 0.56, 0.67, 0.7, 0.67, 0.56, 0.62, 0.75, 0.62, 0.56, 0.56, 0.67, 0.62, 0.62, 0.62, 0.71, 0.5, 0.67, 0.67, 0.62, 0.57, 0.4, 0.75, 0.75, 0.67, 0.44, 0.62, 0.78, 0.36, 0.67, 0.73, 0.7, 0.71, 0.62, 0.75, 0.75, 0.75, 0.75, 0.75, 0.6, 0.67, 0.62, 0.56, 0.8, 0.67, 0.67, 0.78, 0.67, 0.6, 0.4, 0.44, 0.75, 0.56, 0.56, 0.75, 0.22, 0.56, 0.62, 0.78, 0.45, 0.67, 0.44, 0.44, 0.62, 0.5, 0.75, 0.38, 0.56, 0.75, 0.67, 0.78, 0.71, 0.6, 0.78, 0.5, 0.78, 0.67, 0.67, 0.71, 0.43, 0.56, 0.71, 0.67, 0.56, 0.33, 0.44, 0.5, 0.62, 0.75, 0.62, 0.5, 0.44, 0.56, 0.56, 0.67, 0.67, 0.6, 0.45, 0.45, 0.5, 0.55, 0.45, 0.56, 0.56, 0.44, 0.5, 0.44, 0.5, 0.78, 0.62, 0.4, 0.71, 0.56, 0.45, 0.57, 0.62, 0.6, 0.67, 0.43, 0.43, 0.75, 0.75, 0.67, 0.67, 0.58, 0.78, 0.78, 0.38, 0.67, 0.4, 0.4, 0.56, 0.56, 0.56, 0.56, 0.42, 0.56, 0.42, 0.44, 0.62, 0.5, 0.57, 0.56, 0.5, 0.5, 0.5, 0.43, 0.44, 0.67, 0.56, 0.54, 0.38, 0.64, 0.44, 0.42, 0.33, 0.64, 0.64, 0.44, 0.5, 0.44, 0.71, 0.43, 0.75, 0.62, 0.53, 0.45, 0.31, 0.62, 0.57, 0.5, 0.56, 0.5, 0.6, 0.36, 0.29, 0.55, 0.5, 0.62, 0.56, 0.6, 0.29, 0.56, 0.6, 0.45, 0.44, 0.5, 0.44, 0.31, 0.4, 0.5, 0.5, 0.64, 0.45, 0.55, 0.5, 0.62, 0.71, 0.56, 0.56, 0.3, 0.25, 0.5, 0.5, 0.62, 0.4, 0.4, 0.55, 0.62, 0.56, 0.33, 0.45, 0.6, 0.62, 0.5, 0.5, 0.46, 0.46, 0.5, 0.46, 0.6, 0.27, 0.56, 0.6, 0.56, 0.5, 0.55, 0.46, 0.62, 0.4, 0.5, 0.54, 0.57, 0.5, 0.4, 0.5, 0.33, 0.43, 0.55, 0.56, 0.4, 0.57, 0.2, 0.38, 0.53, 0.45, 0.5, 0.5, 0.4, 0.4, 0.56, 0.56, 0.6, 0.44, 0.45, 0.4, 0.36, 0.57, 0.44, 0.5, 0.56, 0.33, 0.56, 0.5, 0.33, 0.45, 0.38, 0.43, 0.4, 0.4, 0.57, 0.57, 0.38, 0.45, 0.4, 0.38, 0.5, 0.57, 0.5, 0.5, 0.6, 0.56, 0.56, 0.56, 0.44, 0.44, 0.44, 0.4, 0.5, 0.5, 0.5, 0.44, 0.3, 0.5, 0.43, 0.4, 0.5, 0.4, 0.6, 0.43, 0.5, 0.5, 0.25, 0.25, 0.45, 0.5, 0.44, 0.5, 0.45, 0.42, 0.3, 0.64, 0.3, 0.33, 0.56, 0.5, 0.62, 0.5, 0.36, 0.36, 0.45, 0.42, 0.57, 0.36, 0.38, 0.31, 0.44, 0.44, 0.4, 0.5, 0.33, 0.3, 0.4, 0.3, 0.5, 0.4, 0.45, 0.33, 0.44, 0.5, 0.46, 0.56, 0.55, 0.4, 0.36, 0.6, 0.17, 0.4, 0.4, 0.4, 0.36, 0.5, 0.56, 0.33, 0.5, 0.54, 0.29, 0.38, 0.5, 0.45, 0.62, 0.27, 0.56, 0.4, 0.3, 0.33, 0.4, 0.29, 0.29, 0.38, 0.5, 0.3, 0.36, 0.38, 0.47, 0.27, 0.4, 0.25, 0.3, 0.4, 0.33, 0.27, 0.33, 0.4, 0.4, 0.55, 0.45, 0.3, 0.42, 0.36, 0.43, 0.5, 0.33, 0.33, 0.36, 0.33, 0.36, 0.45, 0.36, 0.38, 0.22, 0.3, 0.36, 0.23, 0.33, 0.4, 0.36, 0.25, 0.44, 0.18, 0.4, 0.27, 0.46, 0.38, 0.36, 0.23, 0.42, 0.54, 0.19, 0.36, 0.5, 0.27, 0.5, 0.44, 0.5, 0.4, 0.27, 0.4, 0.3, 0.46, 0.43, 0.33, 0.25, 0.27, 0.4, 0.31, 0.42, 0.38, 0.3, 0.3, 0.3, 0.3, 0.3, 0.4, 0.38, 0.33, 0.25, 0.4, 0.3, 0.17, 0.33, 0.33, 0.4, 0.4, 0.4, 0.4, 0.31, 0.29, 0.4, 0.33, 0.31, 0.31, 0.29, 0.29, 0.36, 0.44, 0.17, 0.36, 0.3, 0.36, 0.29, 0.25, 0.31, 0.43, 0.38, 0.38, 0.25, 0.3, 0.27, 0.25, 0.27, 0.43, 0.27, 0.31, 0.31, 0.45, 0.4, 0.3, 0.3, 0.17, 0.15, 0.45, 0.25, 0.36, 0.29, 0.42, 0.27, 0.27, 0.36, 0.33, 0.15, 0.36, 0.18, 0.25, 0.33, 0.25, 0.46, 0.33, 0.21, 0.42, 0.4, 0.22, 0.33, 0.38, 0.25, 0.33, 0.27, 0.45, 0.31, 0.55, 0.46, 0.15, 0.25, 0.29, 0.25, 0.31, 0.32, 0.27, 0.36, 0.44, 0.33, 0.3, 0.25, 0.4, 0.18, 0.31, 0.29, 0.3, 0.36, 0.5, 0.38, 0.43, 0.36, 0.08, 0.22, 0.25, 0.36, 0.36, 0.29, 0.29, 0.38, 0.09, 0.25, 0.27, 0.33, 0.27, 0.11, 0.29, 0.33, 0.38, 0.33, 0.22, 0.29, 0.29, 0.18, 0.23, 0.19, 0.36, 0.31, 0.33, 0.23, 0.33, 0.29, 0.4, 0.23, 0.27, 0.3, 0.27, 0.23, 0.14, 0.17, 0.22, 0.27, 0.36, 0.23, 0.17, 0.23, 0.23, 0.22, 0.31, 0.36, 0.29, 0.27, 0.44, 0.25, 0.31, 0.14, 0.38, 0.06, 0.29, 0.33, 0.2, 0.27, 0.33, 0.25, 0.25, 0.24, 0.31, 0.08, 0.19, 0.23, 0.15, 0.18, 0.33, 0.33, 0.22, 0.29, 0.21, 0.33, 0.2, 0.17, 0.28, 0.2, 0.27, 0.31, 0.25, 0.15, 0.3, 0.33, 0.27, 0.21, 0.29, 0.29, 0.25, 0.3, 0.21, 0.33, 0.27, 0.12, 0.31, 0.2, 0.2, 0.33, 0.27, 0.25, 0.25, 0.25, 0.31, 0.11, 0.25, 0.27, 0.3, 0.31, 0.21, 0.4, 0.31, 0.21, 0.29, 0.2, 0.21, 0.43, 0.33, 0.11, 0.47, 0.08, 0.36, 0.17, 0.27, 0.2, 0.15, 0.21, 0.38, 0.21, 0.21, 0.2, 0.33, 0.28, 0.15, 0.2, 0.17, 0.08, 0.25, 0.29, 0.23, 0.15, 0.08, 0.3, 0.27, 0.25, 0.25, 0.27, 0.35, 0.79, 0.39, 0.55, 1.0, 0.4, 0.33, 0.8, 0.26, 0.64, 0.36, 0.5, 0.56, 0.4, 0.21, 1.0, 0.32, 0.5, 0.6, 0.83, 0.44, 1.0, 0.22, 1.0, 1.0, 0.41, 0.35, 0.25, 0.4, 0.44, 0.24, 0.67, 0.38, 0.41, 0.39, 0.5, 0.27, 0.43, 1.0, 0.5, 0.44, 1.0, 0.77, 0.35, 0.41, 0.5, 0.5, 0.37, 1.0, 0.67, 1.0, 0.62, 0.43, 0.33, 0.32, 0.5, 0.33, 0.2, 0.71, 1.0, 0.5, 0.56, 0.35, 0.5, 0.45, 0.35, 0.5, 0.5, 0.18, 0.53, 0.33, 0.39, 0.77, 0.32, 0.71, 1.0, 0.25, 1.0, 0.55, 0.35, 0.35, 0.44, 0.43, 1.0, 0.43, 1.0, 0.5, 0.47, 0.6, 1.0, 0.43, 0.56, 0.17, 0.6, 0.35, 0.41, 0.47, 0.5, 0.71, 0.35, 0.27, 0.41, 1.0, 0.5, 0.56, 0.27, 0.33, 1.0, 0.5, 0.32, 0.47, 0.9, 1.0, 0.33, 0.57, 1.0, 0.23, 0.9, 0.29, 0.48, 0.62, 0.71, 0.5, 0.71, 0.33, 0.6, 0.2, 0.54, 0.43, 0.47, 0.71, 0.25, 0.77, 0.25, 0.26, 0.9, 0.43, 0.45, 0.6, 0.5, 1.0, 0.48, 0.29, 1.0, 0.35, 0.67, 0.37, 0.19, 0.38, 0.25, 0.25, 0.33, 0.8, 0.33, 0.61, 0.33, 0.3, 0.43, 0.16, 1.0, 0.36, 0.37, 0.2, 0.56, 0.29, 0.46, 0.47, 0.42, 1.0, 0.31, 0.46, 0.5, 0.18, 0.28, 0.35, 0.3, 0.29, 0.41, 0.22, 0.25, 1.0, 0.5, 0.38, 0.27, 0.37, 0.43, 0.9, 0.32, 0.37, 0.67, 0.5, 1.0, 1.0, 0.5, 0.52, 0.2, 0.55, 1.0, 0.67, 1.0, 0.71, 1.0, 0.43, 1.0, 0.5, 0.29, 0.2, 0.5, 0.27, 0.4, 0.33, 0.33, 0.28, 0.41, 0.22, 0.5, 1.0, 0.32, 0.37, 0.36, 0.19, 0.19, 0.32, 0.35, 1.0, 0.47, 0.29, 0.38, 0.6, 0.53, 1.0, 0.25, 0.25, 0.38, 0.5, 0.48, 0.19, 0.44, 0.59, 0.67, 0.32, 0.39, 0.27, 0.71, 0.5, 0.79, 0.4, 0.35, 0.64, 0.53, 0.29, 0.43, 0.25, 0.5, 0.39, 0.22, 0.27, 0.5, 0.18, 0.39, 1.0, 0.5, 0.43, 0.18, 0.6, 0.3, 0.11, 0.11, 0.11, 0.43, 0.4, 0.63, 0.25, 0.27, 0.43, 0.05, 1.0, 0.47, 0.43, 0.43, 0.41, 0.33, 0.5, 0.52, 0.47, 0.5, 0.56, 0.3, 0.35, 0.43, 0.17, 0.7, 0.4, 0.2, 0.37, 0.11, 0.54, 0.67, 0.43, 0.54, 0.71, 0.41, 0.33, 0.5, 0.61, 0.33, 0.43, 0.5, 0.79, 0.5, 0.57, 0.39, 0.5, 0.25, 0.43, 0.45, 0.5, 1.0, 0.26, 0.5, 0.29, 0.54, 0.31, 0.2, 0.44, 0.36, 0.9, 0.71, 0.5, 1.0, 1.0, 0.29, 0.36, 0.9, 0.44, 0.19, 0.25, 0.7, 0.52, 0.55, 0.44, 0.5, 0.5, 0.35, 0.71, 0.25, 0.47, 0.37, 0.58, 0.64, 0.64, 1.0, 0.43, 0.2, 0.25, 0.32, 0.17, 0.32, 1.0, 0.33, 1.0, 0.33, 1.0, 0.53, 1.0, 0.37, 0.5, 0.3, 0.47, 1.0, 0.43, 0.44, 0.25, 0.33, 0.21, 0.47, 0.8, 1.0, 0.57, 0.37, 0.33, 0.43, 0.24, 0.4, 0.6, 0.24, 0.29, 0.38, 0.29, 0.35, 0.44, 0.71, 0.44, 0.67, 0.6, 1.0, 0.55, 0.41, 0.1, 0.47, 0.4, 1.0, 0.43, 0.43, 0.25, 0.29, 0.45, 1.0, 1.0, 0.75, 0.35, 0.6, 0.29, 0.52, 0.67, 0.33, 0.35, 0.61, 0.35, 0.56, 0.8, 0.56, 0.29, 0.5, 0.33, 0.24, 1.0, 1.0, 0.56, 0.33, 0.33, 1.0, 0.44, 1.0, 0.5, 0.54, 0.57, 0.33, 0.38, 0.28, 0.79, 1.0, 0.9, 0.24, 0.9, 0.26, 0.43, 1.0, 0.64, 0.61, 0.32, 0.2, 0.19, 0.39, 0.58, 0.36, 0.47, 0.32, 0.5, 0.25, 0.13, 0.18, 0.19, 0.15, 0.2, 0.14, 0.09, 0.17, 0.07, 0.08, 0.29, 0.06, 0.11, 0.08, 0.12, 0.06, 0.25, 0.07, 0.11, 0.21, 0.06, 0.07, 0.2, 0.2, 0.09, 0.31, 0.17, 0.08, 0.05, 0.07, 0.0, 0.13, 0.25, 0.19, 0.07, 0.07, 0.36, 0.13, 0.13, 0.05, 0.11, 0.13, 0.07, 0.0, 0.17, 0.4, 0.29, 0.19, 0.06, 0.18, 0.22, 0.15, 0.17, 0.13, 0.28, 0.2, 0.15, 0.22, 0.06, 0.07, 0.2, 0.16, 0.13, 0.06, 0.07, 0.2, 0.08, 0.14, 0.05, 0.24, 0.2, 0.18, 0.15, 0.22, 0.12, 0.08, 0.14, 0.1, 0.08, 0.2, 0.25, 0.12, 0.11, 0.1, 0.11, 0.11, 0.12, 0.12, 0.18, 0.23, 0.14, 0.1, 0.11, 0.14, 0.06, 0.16, 0.11, 0.27, 0.16, 0.18, 0.29, 0.15, 0.05, 0.18, 0.22, 0.18, 0.16, 0.24, 0.27, 0.09, 0.12, 0.06, 0.12, 0.09, 0.14, 0.05, 0.1, 0.25, 0.27, 0.15, 0.17, 0.08, 0.09, 0.07, 0.15, 0.27, 0.11, 0.29, 0.08, 0.25, 0.22, 0.12, 0.17, 0.14, 0.36, 0.1, 0.19, 0.11, 0.12, 0.1, 0.06, 0.08, 0.12, 0.09, 0.15, 0.12, 0.06, 0.19, 0.31, 0.07, 0.09, 0.07, 0.09, 0.3, 0.12, 0.13, 0.06, 0.3, 0.13, 0.05, 0.25, 0.06, 0.15, 0.1, 0.15, 0.17, 0.18, 0.44, 0.2, 0.15, 0.16, 0.07, 0.06, 0.0, 0.14, 0.31, 0.0, 0.29, 0.15, 0.0, 0.3, 0.07, 0.2, 0.05, 0.17, 0.13, 0.09, 0.1, 0.22, 0.09, 0.14, 0.22, 0.08, 0.08, 0.14, 0.12, 0.08, 0.12, 0.25, 0.23, 0.1, 0.1, 0.27, 0.1, 0.07, 0.25, 0.1, 0.1, 0.15, 0.07, 0.3, 0.28, 0.06, 0.17, 0.15, 0.19, 0.2, 0.3, 0.22, 0.11, 0.07, 0.07, 0.24, 0.2, 0.15, 0.17, 0.07, 0.1, 0.2, 0.1, 0.0, 0.25, 0.1, 0.07, 0.11, 0.08, 0.11, 0.08, 0.12, 0.18, 0.05, 0.2, 0.07, 0.07, 0.12, 0.17, 0.19, 0.22, 0.08, 0.33, 0.44, 0.33, 0.38, 0.5, 0.43, 0.31, 0.41, 0.36, 0.4, 0.42, 0.38, 0.5, 0.62, 0.47, 0.36, 0.43, 0.44, 0.27, 0.38, 0.3, 0.3, 0.55, 0.33, 0.36, 0.4, 0.33, 0.55, 0.42, 0.33, 0.27, 0.21, 0.29, 0.57, 0.22, 0.46, 0.23, 0.56, 0.29, 0.5, 0.36, 0.43, 0.44, 0.5, 0.32, 0.5, 0.45, 0.45, 0.33, 0.42, 0.31, 0.35, 0.38, 0.31, 0.56, 0.5, 0.33, 0.5, 0.22, 0.57, 0.33, 0.43, 0.38, 0.43, 0.4, 0.33, 0.33, 0.38, 0.33, 0.55, 0.33, 0.4, 0.43, 0.33, 0.33, 0.33, 0.38, 0.4, 0.2, 0.38, 0.64, 0.33, 0.55, 0.31, 0.67, 0.36, 0.33, 0.33, 0.22, 0.4, 0.31, 0.47, 0.38, 0.5, 0.43, 0.57, 0.4, 0.5, 0.3, 0.33, 0.4, 0.33, 0.53, 0.4, 0.38, 0.44, 0.36, 0.29, 0.42, 0.38, 0.5, 0.4, 0.3, 0.33, 0.4, 0.27, 0.38, 0.26, 0.33, 0.38, 0.57, 0.38, 0.45, 0.4, 0.3, 0.33, 0.5, 0.4, 0.5, 0.5, 0.67, 0.25, 0.5, 0.33, 0.36, 0.38, 0.56, 0.33, 0.38, 0.5, 0.4, 0.38, 0.45, 0.27, 0.33, 0.25, 0.33, 0.43, 0.42, 0.38, 0.38, 0.38, 0.5, 0.67, 0.36, 0.36, 0.31, 0.33, 0.53, 0.4, 0.62, 0.22, 0.33, 0.5, 0.36, 0.2, 0.33, 0.55, 0.5, 0.69, 0.4, 0.38, 0.29, 0.33, 0.4, 0.29, 0.4, 0.38, 0.43, 0.42, 0.31, 0.22, 0.55, 0.29, 0.33, 0.2, 0.44, 0.25, 0.5, 0.42, 0.33, 0.33, 0.5, 0.44, 0.18, 0.29, 0.2, 0.17, 0.2, 0.33, 0.4, 0.33, 0.44, 0.38, 0.33, 0.4, 0.33, 0.4, 0.29, 0.38, 0.4, 0.33, 0.33, 0.38, 0.44, 0.5, 0.39, 0.43, 0.5, 0.28, 0.29, 0.33, 0.45, 0.42, 0.36, 0.38, 0.29, 0.31, 0.26, 0.57, 0.5, 0.38, 0.45, 0.43, 0.36, 0.31, 0.3, 0.29, 0.43, 0.33, 0.43, 0.27, 0.29, 0.42, 0.25, 0.57, 0.43, 0.6, 0.5, 0.35, 0.5, 0.62, 0.73, 0.57, 0.67, 0.57, 0.6, 0.62, 0.75, 0.71, 0.83, 0.5, 0.62, 0.56, 0.57, 0.64, 0.8, 0.43, 0.7, 0.62, 0.5, 0.67, 0.75, 0.62, 0.6, 0.43, 0.5, 0.55, 0.62, 0.43, 0.64, 0.44, 0.67, 0.67, 0.75, 0.56, 0.5, 0.38, 0.5, 0.62, 0.67, 0.71, 0.7, 0.46, 0.75, 0.81, 0.75, 0.71, 0.7, 0.5, 0.5, 0.45, 0.62, 0.57, 0.77, 0.6, 0.33, 0.62, 0.69, 0.62, 0.5, 0.64, 0.7, 0.62, 0.57, 0.55, 0.54, 0.7, 0.67, 0.67, 0.5, 0.65, 0.78, 0.56, 0.65, 0.5, 0.62, 0.62, 0.89, 0.7, 0.6, 0.57, 0.64, 0.6, 0.64, 0.67, 0.56, 0.5, 0.12, 0.62, 0.6, 0.62, 0.62, 0.58, 0.5, 0.6, 0.75, 0.71, 0.67, 0.43, 0.43, 0.73, 0.56, 0.75, 0.83, 0.77, 0.75, 0.67, 0.56, 0.67, 0.71, 0.5, 0.62, 0.55, 0.8, 0.67, 0.67, 0.62, 0.64, 0.62, 0.71, 0.82, 0.38, 0.64, 0.67, 0.87, 0.55, 0.44, 0.67, 0.64, 0.67, 0.67, 0.7, 0.57, 0.64, 0.7, 0.67, 0.75, 0.7, 0.5, 0.62, 0.5, 0.57, 0.56, 0.75, 0.72, 0.67, 0.54, 0.71, 0.5, 0.5, 0.56, 0.7, 0.67, 0.75, 0.75, 0.62, 0.73, 0.8, 0.58, 0.61, 0.8, 0.6, 0.5, 0.5, 0.64, 0.64, 0.62, 0.77, 0.64, 0.67, 0.57, 0.43, 0.64, 0.62, 0.82, 0.73, 0.56, 0.62, 0.6, 0.56, 0.53, 0.75, 0.44, 0.84, 0.42, 0.5, 0.57, 0.7, 0.7, 0.53, 0.67, 0.86, 0.67, 0.67, 0.5, 0.75, 0.75, 0.62, 0.77, 0.62, 0.55, 0.7, 0.57, 0.67, 0.73, 0.7, 0.67, 0.67, 0.54, 0.77, 0.83, 0.5, 0.46, 0.62, 0.64, 0.5, 0.67, 0.67, 0.71, 0.69, 0.71, 0.59, 0.56, 0.71, 0.69, 0.61, 0.5, 0.56, 0.62, 0.56, 0.64, 0.6, 0.73, 0.69, 0.67, 0.62, 0.67, 0.62, 0.55, 0.79, 0.67, 0.31, 0.62, 0.78, 0.57, 0.62, 0.5, 0.62, 0.38, 0.45, 0.19, 0.44, 0.5, 0.39, 0.4, 0.38, 0.41, 0.17, 0.25, 0.24, 0.25, 0.28, 0.0, 0.64, 0.36, 0.37, 0.46, 0.27, 0.35, 0.41, 0.5, 0.33, 0.57, 0.6, 0.5, 0.67, 0.33, 0.35, 0.68, 0.33, 0.59, 0.5, 0.41, 0.17, 0.29, 0.52, 0.6, 0.17, 0.37, 0.53, 0.22, 0.53, 0.41, 0.22, 0.6, 0.1, 0.28, 0.4, 0.43, 0.38, 0.48, 0.45, 0.2, 0.39, 0.24, 0.58, 0.6, 0.44, 0.59, 0.36, 0.26, 0.17, 0.47, 0.39, 0.78, 0.3, 0.79, 0.53, 0.67, 0.08, 0.64, 0.4, 0.5, 0.69, 0.27, 0.45, 0.57, 0.67, 0.33, 0.29, 0.56, 0.93, 0.15, 0.62, 0.25, 0.36, 0.55, 0.61, 0.67, 0.47, 0.35, 0.6, 0.46, 0.78, 0.5, 0.71, 0.39, 0.33, 0.22, 0.37, 0.35, 0.22, 0.17, 0.35, 0.29, 0.56, 0.29, 0.53, 0.43, 0.26, 0.53, 0.81, 0.15, 0.22, 0.43, 0.53, 0.78, 0.31, 0.29, 0.39, 0.69, 0.0, 0.12, 0.22, 0.42, 0.78, 0.26, 0.14, 0.4, 0.55, 0.45, 0.41, 0.33, 0.4, 0.24, 0.1, 0.37, 0.67, 0.5, 0.5, 0.48, 0.41, 0.4, 0.28, 0.25, 0.35, 0.52, 0.55, 0.69, 0.47, 0.37, 0.53, 0.45, 0.53, 0.71, 0.57, 0.37, 0.5, 0.2, 0.21, 0.5, 0.67, 0.57, 1.0, 0.54, 0.39, 0.43, 0.4, 0.39, 0.25, 0.25, 0.31, 0.68, 0.53, 0.21, 0.16, 0.69, 0.5, 0.6, 0.37, 0.69, 0.23, 0.56, 0.28, 0.55, 0.56, 0.0, 0.52, 0.79, 0.43, 0.4, 0.78, 0.53, 0.39, 0.38, 0.42, 0.2, 0.17, 0.33, 1.0, 0.17, 0.59, 0.5, 0.69, 0.41, 0.5, 1.0, 0.68, 0.25, 0.15, 0.27, 0.67, 0.48, 0.38, 0.67, 0.56, 0.24, 0.65, 0.25, 0.63, 0.6, 0.12, 0.61, 0.59, 0.38, 0.52, 1.0, 0.6, 0.2, 0.55, 0.43, 0.53, 0.6, 0.93, 0.8, 0.21, 0.39, 0.55, 0.53, 0.78, 0.69, 0.62, 0.6, 0.16, 0.5, 0.85, 0.22, 0.41, 0.32, 0.86, 1.0, 0.43, 0.39, 0.47, 0.32, 0.12, 0.57, 0.5, 0.24, 0.4, 0.29, 0.39, 0.6, 0.24, 0.57, 0.58, 0.57, 0.6, 0.44, 0.29, 0.2, 0.23, 0.68, 0.71, 0.55, 0.38, 0.61, 0.4, 0.22, 0.4, 0.78, 0.38, 0.6, 0.62, 0.43, 0.67, 0.44, 0.15, 0.44, 0.57, 0.78, 0.4, 0.6, 0.2, 0.25, 0.23, 0.52, 0.29, 0.52, 0.5, 0.44, 0.48, 0.29, 0.28, 0.4, 0.32, 0.22, 0.35, 0.78, 0.44, 0.33, 0.44, 0.5, 0.44, 0.79, 0.22, 0.46, 0.46, 0.5, 0.4, 0.22, 0.57, 0.47, 0.31, 0.25, 1.0, 0.6, 0.67, 0.4, 0.3, 0.3, 0.44, 0.42, 0.48, 0.62, 0.42, 0.4, 0.46, 0.64, 0.69, 0.6, 0.6, 0.39, 0.15, 0.36, 0.44, 0.16, 0.21, 1.0, 0.39, 0.5, 0.5, 0.57, 0.5, 0.6, 0.39, 0.35, 0.32, 0.4, 0.47, 0.21, 0.42, 0.67, 0.57, 0.61, 0.2, 0.77, 1.0, 0.4, 0.81, 0.28, 0.3, 0.54, 0.4, 0.26, 0.12, 0.38, 0.15, 0.25, 0.28, 0.21, 0.4, 0.3, 0.44, 0.31, 0.53, 0.3, 0.35, 0.27, 0.39, 1.0, 0.33, 0.48, 0.44, 0.25, 0.12, 0.35, 0.47]) = 0.3512378110760915\n"
     ]
    }
   ],
   "source": [
    "testDistances = list(map(computeSimilarity, inputText))\n",
    "refDistances = [float(value[0]) for value in gsText]\n",
    "pcorr = pearsonr(refDistances, testDistances)[0]\n",
    "\n",
    "# formatting for purely demonstrative purposes\n",
    "print(f\"pearsonr({list(map(lambda x:float('%.2f' % x), refDistances))}, {list(map(lambda x:float('%.2f' % x), testDistances))}) = {pcorr}\")"
   ]
  },
  {
   "source": [
    "***\n",
    "\n",
    "## Conlusion"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In this session, the test set was evaluated using NE tagging. In this implementation, every named entity in the sentences was replaced by the tag that they were detected as p.e: Victor Badenas was replaced by PERSON. From this, the jaccard distance was computed and a correlation of 0.35 was obtained. This value is surprisingly low considering that this processing removes the dependancy on the variability of places, names and dates. However, due to time constraints, i have not been able to develop it further."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "***\n",
    "\n",
    "### End of P4"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}