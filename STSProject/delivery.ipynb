{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STS PROJECT - SEMANTIC TEXTUAL SIMILARITY\n",
    "- Andrea Masi\n",
    "- Victor Badenas\n",
    "\n",
    "***\n",
    "\n",
    "## INTRODUCTION\n",
    "In this project we proposed a solution for the task included in the SemEval (Semantic Evaluation Exercises), a series of workshops which have the main aim of the evaluation and comparision of semantic analysis systems.\n",
    "\n",
    "The task done has been Semantic Textual Similarity (STS), also known as paraphrases detection. A measure of similarity between two sentences.\n",
    "\n",
    "This notebook contains the methodology and procedures used to obtain the result shown at the end of the notebook. We propose an approach where the distance between two sentences is characterized by a vector composed of different traditional similarity metrics in NLP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Module Imports\n",
    "Importing necessary modules for the notebook.\n",
    "\n",
    "From packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from nltk.metrics.distance import jaccard_distance\n",
    "from collections.abc import Iterable\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/victorbadenas/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/victorbadenas/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet_ic to\n",
      "[nltk_data]     /home/victorbadenas/nltk_data...\n",
      "[nltk_data]   Package wordnet_ic is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from data_utils import load_data\n",
    "from dimension.lexical import *\n",
    "from dimension.syntactical import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Data\n",
    "The data is loaded using a function from the `data_utils.py` file which will load a dataframe, read from a tsv file, containing all pairs of sentences as well as their gold standard. If the tsv does not exist, it will be automatically created from all sentences in the containing folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data samples: 2234, test_data samples: 3108\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = load_data('data/')\n",
    "print(\n",
    "    f\"train_data samples: {len(train_data)}, test_data samples: {len(test_data)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display of the first 5 data points from the train_data DataFrame and the test_data DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>Gs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>But other sources close to the sale said Viven...</td>\n",
       "      <td>But other sources close to the sale said Viven...</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Micron has declared its first quarterly profit...</td>\n",
       "      <td>Micron's numbers also marked the first quarter...</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The fines are part of failed Republican effort...</td>\n",
       "      <td>Perry said he backs the Senate's efforts, incl...</td>\n",
       "      <td>2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The American Anglican Council, which represent...</td>\n",
       "      <td>The American Anglican Council, which represent...</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The tech-loaded Nasdaq composite rose 20.96 po...</td>\n",
       "      <td>The technology-laced Nasdaq Composite Index &lt;....</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  S1  \\\n",
       "0  But other sources close to the sale said Viven...   \n",
       "1  Micron has declared its first quarterly profit...   \n",
       "2  The fines are part of failed Republican effort...   \n",
       "3  The American Anglican Council, which represent...   \n",
       "4  The tech-loaded Nasdaq composite rose 20.96 po...   \n",
       "\n",
       "                                                  S2    Gs  \n",
       "0  But other sources close to the sale said Viven...  4.00  \n",
       "1  Micron's numbers also marked the first quarter...  3.75  \n",
       "2  Perry said he backs the Senate's efforts, incl...  2.80  \n",
       "3  The American Anglican Council, which represent...  3.40  \n",
       "4  The technology-laced Nasdaq Composite Index <....  2.40  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>Gs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The problem likely will mean corrective change...</td>\n",
       "      <td>He said the problem needs to be corrected befo...</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The technology-laced Nasdaq Composite Index .I...</td>\n",
       "      <td>The broad Standard &amp; Poor's 500 Index .SPX inc...</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"It's a huge black eye,\" said publisher Arthur...</td>\n",
       "      <td>\"It's a huge black eye,\" Arthur Sulzberger, th...</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SEC Chairman William Donaldson said there is a...</td>\n",
       "      <td>\"I think there's a building confidence that th...</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vivendi shares closed 1.9 percent at 15.80 eur...</td>\n",
       "      <td>In New York, Vivendi shares were 1.4 percent d...</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  S1  \\\n",
       "0  The problem likely will mean corrective change...   \n",
       "1  The technology-laced Nasdaq Composite Index .I...   \n",
       "2  \"It's a huge black eye,\" said publisher Arthur...   \n",
       "3  SEC Chairman William Donaldson said there is a...   \n",
       "4  Vivendi shares closed 1.9 percent at 15.80 eur...   \n",
       "\n",
       "                                                  S2   Gs  \n",
       "0  He said the problem needs to be corrected befo...  4.4  \n",
       "1  The broad Standard & Poor's 500 Index .SPX inc...  0.8  \n",
       "2  \"It's a huge black eye,\" Arthur Sulzberger, th...  3.6  \n",
       "3  \"I think there's a building confidence that th...  3.4  \n",
       "4  In New York, Vivendi shares were 1.4 percent d...  1.4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Similarity functions\n",
    "Declaration of the 4 basic similarity functions that will be used pfor this task: jaccard, overlap, cosine and dice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(s1, s2):\n",
    "    assert isinstance(s1, Iterable), f\"s1 must be an iterable, not {type(s1)}\"\n",
    "    assert isinstance(s2, Iterable), f\"s2 must be an iterable, not {type(s2)}\"\n",
    "    return 1 - jaccard_distance(set(s1), set(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_similarity(s1, s2):\n",
    "    assert isinstance(s1, Iterable), f\"s1 must be an iterable, not {type(s1)}\"\n",
    "    assert isinstance(s2, Iterable), f\"s2 must be an iterable, not {type(s2)}\"\n",
    "    s1 = set(s1)\n",
    "    s2 = set(s2)\n",
    "    intersection = s1.intersection(s2)\n",
    "    return len(intersection) / min(len(s1), len(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(s1, s2):\n",
    "    assert isinstance(s1, Iterable), f\"s1 must be an iterable, not {type(s1)}\"\n",
    "    assert isinstance(s2, Iterable), f\"s2 must be an iterable, not {type(s2)}\"\n",
    "    s1 = set(s1)\n",
    "    s2 = set(s2)\n",
    "    intersection = s1.intersection(s2)\n",
    "    return len(intersection) / ((len(s1) * len(s2))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_similarity(s1, s2):\n",
    "    assert isinstance(s1, Iterable), f\"s1 must be an iterable, not {type(s1)}\"\n",
    "    assert isinstance(s2, Iterable), f\"s2 must be an iterable, not {type(s2)}\"\n",
    "    s1 = set(s1)\n",
    "    s2 = set(s2)\n",
    "    intersection = s1.intersection(s2)\n",
    "    return 2 * len(intersection) / (len(s1) + len(s2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Feature loading\n",
    "Section devoted to transform each pair of sentences to a vector formed from difference distance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature vector builder for dataframe of sentence pairs\n",
    "\n",
    "Declaration of the function responsible for the iteration over the dataframe containing the sentence pairs (other columns shall be unused). Requires the sentences columns' to be named `\"S1\"` and `\"S2\"`.\n",
    "\n",
    "Returns a numpy array of shape `(n_sentence_pairs, n_features)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(df: pd.DataFrame):\n",
    "    assert \"S1\" in df.columns, \"S1 not in dataframe\"\n",
    "    assert \"S2\" in df.columns, \"S2 not in dataframe\"\n",
    "\n",
    "    features = [None] * len(df)  #preallocated for memory efficiency\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        sentence1, sentence2 = row['S1'], row['S2']\n",
    "\n",
    "        # Get all words\n",
    "        tokenized_1, tokenized_2 = get_tokenized_sentences(\n",
    "            sentence1, sentence2, return_unique_words=False)\n",
    "        tokenized_lc_1, tokenized_lc_2 = get_tokenized_sentences_lowercase(\n",
    "            tokenized_1, tokenized_2, return_unique_words=False)\n",
    "\n",
    "        # Get words without stopwords\n",
    "        no_stopwords_1, no_stopwords_2 = filter_stopwords(\n",
    "            tokenized_1, tokenized_2, return_unique_words=False)\n",
    "        no_stopwords_lc_1, no_stopwords_lc_2 = filter_stopwords(\n",
    "            tokenized_lc_1, tokenized_lc_2, return_unique_words=False)\n",
    "\n",
    "        # Lemmas\n",
    "        lemmatized_1, lemmatized_2 = get_lemmas(tokenized_1,\n",
    "                                                tokenized_2,\n",
    "                                                return_unique_words=False)\n",
    "        lemmatized_lc_1, lemmatized_lc_2 = get_lemmas(\n",
    "            tokenized_lc_1, tokenized_lc_2, return_unique_words=False)\n",
    "\n",
    "        # Name entities\n",
    "        sentence_ne_1, sentence_ne_2 = get_named_entities(\n",
    "            tokenized_1, tokenized_2)\n",
    "\n",
    "        #lemmas cleaned from stopwords\n",
    "        stopwords_and_lemmas1, stopwords_and_lemmas2 = get_lemmas(\n",
    "            no_stopwords_1, no_stopwords_2, return_unique_words=False)\n",
    "\n",
    "        stopwords_and_lemmas_lc_1, stopwords_and_lemmas_lc_2 = get_lemmas(\n",
    "            no_stopwords_lc_1, no_stopwords_lc_2, return_unique_words=False)\n",
    "\n",
    "        # Name entities without stopwords in lowercase\n",
    "        ne_no_stopwords_1, ne_no_stopwords_2 = filter_stopwords(\n",
    "            sentence_ne_1,\n",
    "            sentence_ne_2,\n",
    "            return_unique_words=False,\n",
    "            filter_and_return_in_lowercase=True)\n",
    "\n",
    "        # Name entities without stopwords in lowercase and lemmas\n",
    "        ne_no_stopwords_lemmas_1, ne_no_stopwords_lemmas_2 = get_lemmas(\n",
    "            ne_no_stopwords_1, ne_no_stopwords_2, return_unique_words=False)\n",
    "\n",
    "        # Bigrams\n",
    "        bigrams_1, bigrams_2 = get_ngrams(no_stopwords_1, no_stopwords_2, n=2)\n",
    "        trigrams_1, trigrams_2 = get_ngrams(no_stopwords_1,\n",
    "                                            no_stopwords_2,\n",
    "                                            n=3)\n",
    "\n",
    "        # Bigrams trigrams with sentence tokenizer\n",
    "        bigrams_sent_1, bigrams_sent_2 = get_ngrams_with_sent_tokenize(\n",
    "            sentence1, sentence2, n=2)\n",
    "        trigrams_sent_1, trigrams_sent_2 = get_ngrams_with_sent_tokenize(\n",
    "            sentence1, sentence2, n=3)\n",
    "\n",
    "        # Lesk\n",
    "        lesk_1, lesk_2 = get_lesk_sentences(tokenized_1, tokenized_2)\n",
    "        lesk_lc_1, lesk_lc_2 = get_lesk_sentences(tokenized_lc_1,\n",
    "                                                  tokenized_lc_2)\n",
    "\n",
    "        # Stemmer\n",
    "        stemmed_1, stemmed_2 = get_stemmed_sentences(sentence1, sentence2)\n",
    "\n",
    "        # Synset\n",
    "        average_path = get_synset_similarity(tokenized_1, tokenized_2, \"path\")\n",
    "        average_lch = get_synset_similarity(tokenized_1, tokenized_2, \"lch\")\n",
    "        average_wup = get_synset_similarity(tokenized_1, tokenized_2, \"wup\")\n",
    "        average_lin = get_synset_similarity(tokenized_1, tokenized_2, \"lin\")\n",
    "\n",
    "        average_lc_path = get_synset_similarity(tokenized_lc_1, tokenized_lc_2,\n",
    "                                                \"path\")\n",
    "        average_lc_lch = get_synset_similarity(tokenized_lc_1, tokenized_lc_2,\n",
    "                                               \"lch\")\n",
    "        average_lc_wup = get_synset_similarity(tokenized_lc_1, tokenized_lc_2,\n",
    "                                               \"wup\")\n",
    "        average_lc_lin = get_synset_similarity(tokenized_lc_1, tokenized_lc_2,\n",
    "                                               \"lin\")\n",
    "\n",
    "        # ALL Features\n",
    "        features[index] = [\n",
    "            jaccard_similarity(tokenized_1, tokenized_2),\n",
    "            jaccard_similarity(tokenized_lc_1, tokenized_lc_2),\n",
    "            jaccard_similarity(no_stopwords_1, no_stopwords_2),\n",
    "            jaccard_similarity(no_stopwords_lc_1, no_stopwords_lc_2),\n",
    "            jaccard_similarity(lemmatized_1, lemmatized_2),\n",
    "            jaccard_similarity(lemmatized_lc_1, lemmatized_lc_2),\n",
    "            jaccard_similarity(sentence_ne_1, sentence_ne_2),\n",
    "            jaccard_similarity(stopwords_and_lemmas1, stopwords_and_lemmas2),\n",
    "            jaccard_similarity(stopwords_and_lemmas_lc_1, stopwords_and_lemmas_lc_2),\n",
    "            jaccard_similarity(bigrams_1, bigrams_2),\n",
    "            jaccard_similarity(trigrams_1, trigrams_2),\n",
    "            jaccard_similarity(bigrams_sent_1, bigrams_sent_2),\n",
    "            jaccard_similarity(trigrams_sent_1, trigrams_sent_2),\n",
    "            jaccard_similarity(lesk_1, lesk_2),\n",
    "            jaccard_similarity(lesk_lc_1, lesk_lc_2),\n",
    "            jaccard_similarity(stemmed_1, stemmed_2),\n",
    "            dice_similarity(tokenized_1, tokenized_2),\n",
    "            dice_similarity(tokenized_lc_1, tokenized_lc_2),\n",
    "            dice_similarity(no_stopwords_1, no_stopwords_2),\n",
    "            dice_similarity(no_stopwords_lc_1, no_stopwords_lc_2),\n",
    "            dice_similarity(lemmatized_1, lemmatized_2),\n",
    "            dice_similarity(lemmatized_lc_1, lemmatized_lc_2),\n",
    "            dice_similarity(sentence_ne_1, sentence_ne_2),\n",
    "            dice_similarity(stopwords_and_lemmas1, stopwords_and_lemmas2),\n",
    "            dice_similarity(stopwords_and_lemmas_lc_1, stopwords_and_lemmas_lc_2),\n",
    "            dice_similarity(bigrams_1, bigrams_2),\n",
    "            dice_similarity(trigrams_1, trigrams_2),\n",
    "            dice_similarity(bigrams_sent_1, bigrams_sent_2),\n",
    "            dice_similarity(trigrams_sent_1, trigrams_sent_2),\n",
    "            dice_similarity(lesk_1, lesk_2),\n",
    "            dice_similarity(lesk_lc_1, lesk_lc_2),\n",
    "            dice_similarity(stemmed_1, stemmed_2),\n",
    "            average_path,\n",
    "            average_lch,\n",
    "            average_wup,\n",
    "            average_lin,\n",
    "            average_lc_path,\n",
    "            average_lc_lch,\n",
    "            average_lc_wup,\n",
    "            average_lc_lin\n",
    "        ]\n",
    "        # BEST Features selection for SVR\n",
    "        \"\"\"features[index] = [\n",
    "            jaccard_similarity(tokenized_1, tokenized_2),\n",
    "            jaccard_similarity(no_stopwords_lc_1, no_stopwords_lc_2),\n",
    "            jaccard_similarity(sentence_ne_1, sentence_ne_2),\n",
    "            jaccard_similarity(stopwords_and_lemmas1, stopwords_and_lemmas2),\n",
    "            jaccard_similarity(trigrams_1, trigrams_2),\n",
    "            jaccard_similarity(trigrams_sent_1, trigrams_sent_2),\n",
    "            jaccard_similarity(lesk_1, lesk_2),\n",
    "            jaccard_similarity(lesk_lc_1, lesk_lc_2),\n",
    "            jaccard_similarity(stemmed_1, stemmed_2),\n",
    "            dice_similarity(tokenized_1, tokenized_2),\n",
    "            dice_similarity(no_stopwords_1, no_stopwords_2),\n",
    "            dice_similarity(no_stopwords_lc_1, no_stopwords_lc_2),\n",
    "            dice_similarity(stopwords_and_lemmas_lc_1,\n",
    "                            stopwords_and_lemmas_lc_2),\n",
    "            dice_similarity(bigrams_1, bigrams_2), average_lin, average_lc_lch,\n",
    "            average_lc_wup, average_lc_lin\n",
    "        ]\"\"\"\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features extraction\n",
    "\n",
    "Using the function declared above, the features are extracted from the `train_data` dataframe. Also the Gold Standard is extracted from its column in the dataframe. The shapes for both numpy vectors are displayed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_features.shape: (2234, 40)\n",
      "train_gs.shape: (2234,)\n"
     ]
    }
   ],
   "source": [
    "train_features = get_features(train_data)\n",
    "train_gs = train_data['Gs'].to_numpy()\n",
    "print(f\"train_features.shape: {train_features.shape}\")\n",
    "print(f\"train_gs.shape: {train_gs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_features.shape: (3108, 40)\n",
      "train_gs.shape: (3108,)\n"
     ]
    }
   ],
   "source": [
    "test_features = get_features(test_data)\n",
    "test_gs = test_data['Gs'].to_numpy()\n",
    "print(f\"train_features.shape: {test_features.shape}\")\n",
    "print(f\"train_gs.shape: {test_gs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling\n",
    "\n",
    "features are scaled using sklearns StandardScaler, where the mean is substracted for each feature and it's divided by the variance of the feature to obtain a unified feature space with zero mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train_features)\n",
    "train_features_scaled = scaler.transform(train_features)\n",
    "test_features_scaled = scaler.transform(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection\n",
    "\n",
    "4 different architectures were trained using all available features for the data\n",
    "- NNR: Nearest neighbors regressor using `KNeighborsRegressor` from `sklearn.neighbors`. \n",
    "- MLP: Multi-layer perceptron using `MLPRegressor` from `sklearn.neural_network`.\n",
    "- SVR: Support vector regressor `SVR` from `sklearn.svm`.\n",
    "- MLP with a bottleneck layer: Same as the one defined before, but now with a hidden layer smaller than the number of features and a bigger one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split definition for GridSearch\n",
    "For the correct search of the best model, a predefined split has to be defined to ensure that the model is selected using the data provided. `np.ndarrays` are defined containing all the data and all the labels concatenated and then an identifyer array is passed onto the `PredefinedSplit` for it to know which samples belong to the train set (`-1` label) and to the n fold (in our case just 1) test set (label `0`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5342, 40) (5342,)\n"
     ]
    }
   ],
   "source": [
    "all_data = np.concatenate([train_features_scaled, test_features_scaled])\n",
    "all_labels = np.concatenate([train_gs, test_gs])\n",
    "test_fold = np.array([-1]*train_features_scaled.shape[0] + [0]*test_features_scaled.shape[0])\n",
    "print(all_data.shape, test_fold.shape)\n",
    "ps = PredefinedSplit(test_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of the pearson correlation for the GridSearchCV module\n",
    "The `GridSearchCV` module makes use of a scoring function to determine which model is the optimal given a set of parameters and options. Because our goal is to maximize the pearson correlation in the test set it makes sense to declare a scoring function with a custom metric for it to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_scorer = make_scorer(lambda y, y_hat: pearsonr(y, y_hat)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neirest Neighbors Regressor\n",
    "The first model to be evaluated will be a NNR and the parameters for which the model will be evaluated are: weight configurations, n_neighbords, the different algorithms, the number of leaf sizes and the p value for the minkowski distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1500 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:   19.7s\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 438 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 788 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1238 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1500 out of 1500 | elapsed: 10.3min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "weights = ['uniform', 'distance']\n",
    "nn = list(range(10, 101, 10))\n",
    "algorithms = ['ball_tree', 'kd_tree', 'brute']\n",
    "leaf_sizes = list(range(1, 51, 10))\n",
    "pvalues = list(range(1, 6))\n",
    "\n",
    "nn_params = dict(n_neighbors=nn, weights=weights, p=pvalues, leaf_size=leaf_sizes, algorithm=algorithms)\n",
    "\n",
    "nnr = KNeighborsRegressor()\n",
    "nnrmlp = GridSearchCV(nnr,\n",
    "                      nn_params,\n",
    "                      cv=ps,\n",
    "                      scoring=pearson_scorer,\n",
    "                      n_jobs=-1,\n",
    "                      verbose=1)\n",
    "\n",
    "nnrmlp = nnrmlp.fit(all_data, all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "definition of the algorithm with the best parameters of the gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='kd_tree', leaf_size=41, n_neighbors=20,\n",
       "                    weights='distance')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnr_best_params = nnrmlp.best_params_\n",
    "best_nnr = KNeighborsRegressor(**nnr_best_params)\n",
    "best_nnr.fit(train_features_scaled, train_gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 158 ms, sys: 0 ns, total: 158 ms\n",
      "Wall time: 157 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_nnr_predictions = best_nnr.predict(train_features_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 221 ms, sys: 0 ns, total: 221 ms\n",
      "Wall time: 221 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_nnr_predictions = best_nnr.predict(test_features_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NNR Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train pearsonr:  0.9999533582224034\n",
      "Test pearsonr:  0.6999190047319795\n",
      "Best model parameters:\n",
      "\talgorithm: kd_tree\n",
      "\tleaf_size: 41\n",
      "\tn_neighbors: 20\n",
      "\tp: 2\n",
      "\tweights: distance\n"
     ]
    }
   ],
   "source": [
    "train_nnr_correlation = pearsonr(train_nnr_predictions, train_gs)[0]\n",
    "test_nnr_correlation = pearsonr(test_nnr_predictions, test_gs)[0]\n",
    "print('Train pearsonr: ', train_nnr_correlation)\n",
    "print(\"Test pearsonr: \", test_nnr_correlation)\n",
    "print(\"Best model parameters:\")\n",
    "for k, v in nnr_best_params.items():\n",
    "    print(f\"\\t{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Layer Perceptron Regressor\n",
    "The second model to be evaluated will be a MLPR and the parameters for which the model will be evaluated are: alphas and the hidden_layer_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 180 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  1.3min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "alphas = np.logspace(-6, -1, 6)\n",
    "hidden_layer_sizes = [(i,) for i in range(5, 305, 10)]\n",
    "mlp_param = dict(alpha=alphas, hidden_layer_sizes=hidden_layer_sizes)\n",
    "\n",
    "mlpr = MLPRegressor(max_iter=1000, random_state=1)\n",
    "mgsmlp = GridSearchCV(mlpr,\n",
    "                      mlp_param,\n",
    "                      cv=ps,\n",
    "                      scoring=pearson_scorer,\n",
    "                      n_jobs=-1,\n",
    "                      verbose=1)\n",
    "mgsmlp = mgsmlp.fit(all_data, all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "definition of the algorithm with the best parameters of the gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(alpha=0.1, hidden_layer_sizes=(285,), max_iter=1000,\n",
       "             random_state=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_best_params = mgsmlp.best_params_\n",
    "best_mlp = MLPRegressor(max_iter=1000, random_state=1, **mlp_best_params)\n",
    "best_mlp.fit(train_features_scaled, train_gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17 ms, sys: 7.96 ms, total: 24.9 ms\n",
      "Wall time: 5.83 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_mlp_predictions = best_mlp.predict(train_features_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.4 ms, sys: 4.12 ms, total: 30.5 ms\n",
      "Wall time: 6.21 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_mlp_predictions = best_mlp.predict(test_features_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train pearsonr: 0.8787936099286511\n",
      "Test pearsonr:  0.7197486862008735\n",
      "Best model parameters:\n",
      "\talpha: 0.1\n",
      "\thidden_layer_sizes: (285,)\n"
     ]
    }
   ],
   "source": [
    "train_mlp_correlation = pearsonr(train_mlp_predictions, train_gs)[0]\n",
    "test_mlp_correlation = pearsonr(test_mlp_predictions, test_gs)[0]\n",
    "print('Train pearsonr:', train_mlp_correlation)\n",
    "print(\"Test pearsonr: \", test_mlp_correlation)\n",
    "print(\"Best model parameters:\")\n",
    "for k, v in mlp_best_params.items():\n",
    "    print(f\"\\t{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottleneck MLP\n",
    "After an assumption that the number of features were too many and the model was overfitting. An additional layer of a number of nodes smaller than the number of features was used to reduce the complexity of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1110 candidates, totalling 1110 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 438 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 788 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1110 out of 1110 | elapsed:  7.1min finished\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "bottleneck_length = range(3, test_features.shape[-1])\n",
    "hidden_layer_length = range(4, 100, 20)\n",
    "alphas_lin = np.linspace(0, 1, 6)\n",
    "hidden_layer_sizes = list(product(bottleneck_length, hidden_layer_length))\n",
    "\n",
    "param = dict(hidden_layer_sizes=hidden_layer_sizes, alpha=alphas_lin)\n",
    "\n",
    "bmlp = MLPRegressor(max_iter=500, random_state=1)\n",
    "gsbmlp = GridSearchCV(bmlp,\n",
    "                          param,\n",
    "                          cv=ps,\n",
    "                          scoring=pearson_scorer,\n",
    "                          n_jobs=-1,\n",
    "                          verbose=1)\n",
    "gsbmlp = gsbmlp.fit(all_data, all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "definition of the algorithm with the best parameters of the gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(alpha=1.0, hidden_layer_sizes=(9, 84), max_iter=500,\n",
       "             random_state=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bt_mlp_best_params = gsbmlp.best_params_\n",
    "best_bt_mlp = MLPRegressor(max_iter=500, random_state=1, **bt_mlp_best_params)\n",
    "best_bt_mlp.fit(train_features_scaled, train_gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.6 ms, sys: 0 ns, total: 11.6 ms\n",
      "Wall time: 2.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_bt_mlp_predictions = best_bt_mlp.predict(train_features_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.3 ms, sys: 0 ns, total: 14.3 ms\n",
      "Wall time: 4.56 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_bt_mlp_predictions = best_bt_mlp.predict(test_features_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottleneck MLP Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train pearsonr:  0.8545895366971805\n",
      "Test pearsonr:  0.7336318188483206\n",
      "Best model parameters:\n",
      "\talpha: 1.0\n",
      "\thidden_layer_sizes: (9, 84)\n"
     ]
    }
   ],
   "source": [
    "train_bt_mlp_correlation = pearsonr(train_bt_mlp_predictions, train_gs)[0]\n",
    "test_bt_mlp_correlation = pearsonr(test_bt_mlp_predictions, test_gs)[0]\n",
    "print('Train pearsonr: ', train_bt_mlp_correlation)\n",
    "print('Test pearsonr: ', test_bt_mlp_correlation)\n",
    "print(\"Best model parameters:\")\n",
    "for k, v in bt_mlp_best_params.items():\n",
    "    print(f\"\\t{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR\n",
    "The last model to be tested is an SVR. The parameters to be searched are: gamma, C and epsilon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 840 candidates, totalling 840 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done 438 tasks      | elapsed:   19.5s\n",
      "[Parallel(n_jobs=-1)]: Done 788 tasks      | elapsed:   36.6s\n",
      "[Parallel(n_jobs=-1)]: Done 840 out of 840 | elapsed:   40.0s finished\n"
     ]
    }
   ],
   "source": [
    "gammas = np.logspace(-6, -1, 6)\n",
    "Cs = np.array([0.5, 1, 2, 4, 8, 10, 15, 20, 50, 100, 200, 375, 500, 1000])\n",
    "epsilons = np.linspace(0.1, 1, 10)\n",
    "svm_param = dict(gamma=gammas, C=Cs, epsilon=epsilons)\n",
    "\n",
    "svr = SVR(kernel='rbf', tol=1)\n",
    "gssvr = GridSearchCV(svr,\n",
    "                     svm_param,\n",
    "                     cv=ps,\n",
    "                     scoring=pearson_scorer,\n",
    "                     n_jobs=-1,\n",
    "                     verbose=1)\n",
    "gssvr = gssvr.fit(all_data, all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "definition of the algorithm with the best parameters of the gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(gamma=0.1, tol=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_best_params = gssvr.best_params_\n",
    "best_svr = SVR(kernel='rbf', tol=1, **svr_best_params)\n",
    "best_svr.fit(train_features_scaled, train_gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 112 ms, sys: 60 Âµs, total: 112 ms\n",
      "Wall time: 111 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_svm_predictions = best_svr.predict(train_features_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 155 ms, sys: 0 ns, total: 155 ms\n",
      "Wall time: 158 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_svm_predictions = best_svr.predict(test_features_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train pearsonr: 0.8995633919315202\n",
      "Test pearsonr:  0.7285741569591626\n",
      "Best model parameters:\n",
      "\tC: 1.0\n",
      "\tepsilon: 0.1\n",
      "\tgamma: 0.1\n"
     ]
    }
   ],
   "source": [
    "train_svm_correlation = pearsonr(train_svm_predictions, train_gs)[0]\n",
    "test_svm_correlation = pearsonr(test_svm_predictions, test_gs)[0]\n",
    "print('Train pearsonr:', train_svm_correlation)\n",
    "print(\"Test pearsonr: \", test_svm_correlation)\n",
    "print(\"Best model parameters:\")\n",
    "for k, v in svr_best_params.items():\n",
    "    print(f\"\\t{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          train      test\n",
      "SVR    0.899563  0.728574\n",
      "MLP    0.878794  0.719749\n",
      "NNR    0.999953  0.699919\n",
      "BtBLP  0.854590  0.733632\n"
     ]
    }
   ],
   "source": [
    "correlations = {\n",
    "    \"SVR\": {\"train\": train_svm_correlation,\"test\": test_svm_correlation},\n",
    "    \"MLP\": {\"train\": train_mlp_correlation,\"test\": test_mlp_correlation},\n",
    "    \"NNR\": {\"train\": train_nnr_correlation,\"test\": test_nnr_correlation},\n",
    "    \"BtBLP\": {\"train\": train_bt_mlp_correlation,\"test\": test_bt_mlp_correlation},\n",
    "}\n",
    "print(pd.DataFrame.from_dict(correlations, orient=\"index\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model trained with the bottleeneck mlp yields the best results however, as the goal is to select a model on which perform some feature selction in, the SVR is the model that seems to be more promising given the capability of the SVR models have to generalize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Feature Selection\n",
    "The feature selection process has been performed on a `.py` file also annexed called `forward_search.py`. It has not been annexed to the notebook as the runtime was of several hours and would not give any additional information to run it embedded on the notebook. However, the results will be discussed in the notebook. \n",
    "\n",
    "40 features were defined in the vectors describing each pair of sentences. To search for all combinations of the possible features in the feature space would be a very computationally expensive task as the number of combinations to test would be:\n",
    "\n",
    "$P=\\sum^{N}_{i=1} \\frac{N!}{(N-i)!}$\n",
    "\n",
    "Which is very computationally intensive. For that reason a forward search approach has been taken where, starting from the feature better correlated with the ground truth, all combinations of the best and another feature are tried and then the best is selected. this is done iteratively until all features have been selected. With this method it is possible to select a suboptimal set of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are as shown on the next table:\n",
    "\n",
    "|next_best_feature_index|feature_name|svm_train_pearson|svm_test_pearson|\n",
    "|---|---|---|---|\n",
    "|24|st_lemmas_lc_dice|na|na|\n",
    "|25|bigrams_dice|0.7569018439|0.6701654144|\n",
    "|3|no_stop_lc_jaccard|0.7928514893|0.6885382776|\n",
    "|15|stemmed_jaccard|0.8098010284|0.7011783941|\n",
    "|18|no_stop_dice|0.832851473|0.7177098951|\n",
    "|38|average_lc_wup|0.8350481895|0.7249467512|\n",
    "|37|average_lc_lch|0.8465025219|0.7345462925|\n",
    "|35|average_lin|0.848472905|0.7441819896|\n",
    "|16|tokenized_dice|0.8537878611|0.7443287688|\n",
    "|6|ne_jaccard|0.8566475295|0.7415489911|\n",
    "|39|average_lc_lin|0.8592710204|0.7438845148|\n",
    "|0|tokenized_jaccard|0.8553386682|0.7416358703|\n",
    "|14|lesk_lc_jaccard|0.8559150716|0.7411532023|\n",
    "|19|no_stop_lc_dice|0.859945113|0.7399740251|\n",
    "|13|lesk_jaccard|0.8579436501|0.7418736685|\n",
    "|12|trigrams_sent_jaccard|0.8640442114|0.745306467|\n",
    "|7|st_lemmas _jaccard|0.8648808183|0.7427944038|\n",
    "|10|trigrams_jaccard|0.8659545425|0.7456997951|\n",
    "|34|average_wup|0.8691527762|0.7437638538|\n",
    "|33|average_lch|0.8699168309|0.7444932807|\n",
    "|11|bigrams_sent_jaccard|0.8735932779|0.745160831|\n",
    "|9|bigrams_jaccard|0.8726765445|0.7433300457|\n",
    "|8|st_lemmas_lc_jaccard|0.875144412|0.7430640178|\n",
    "|22|ne_dice|0.8748713591|0.7436311865|\n",
    "|21|lemmas_lc_dice|0.8715725166|0.7427397658|\n",
    "|29|lesk_dice|0.8653357973|0.7419653444|\n",
    "|32|average_path|0.8739536114|0.7415179342|\n",
    "|26|trigrams_dice|0.8680233841|0.7399533417|\n",
    "|23|st_lemmas _dice|0.8745521205|0.7411973361|\n",
    "|36|average_lc_path|0.8781954367|0.7405314764|\n",
    "|4|lemmas_jaccard|0.8874922457|0.7393197223|\n",
    "|2|no_stop_jaccard|0.8869535884|0.7402972782|\n",
    "|1|tokenized_lc_jaccard|0.8889006827|0.7371574177|\n",
    "|28|trigrams_sent_dice|0.8926597158|0.7385353635|\n",
    "|27|bigrams_sent_dice|0.8912935486|0.7375904386|\n",
    "|17|tokenized_lc_dice|0.8889953345|0.7364385229|\n",
    "|30|lesk_lc_dice|0.8930292877|0.7345804535|\n",
    "|5|lemmas_lc_jaccard|0.8962334904|0.7336561523|\n",
    "|0|lemmas_dice|0.8959995979|0.7326778371|\n",
    "|31|stemmed_dice|0.8995633919|0.728574157|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous table, it can be seen that the best result were yielded using the features: \\[0, 3, 6, 7, 10, 12, 13, 14, 15, 16, 18, 19, 24, 25, 35, 37, 38, 39\\] with a 0.7456997951 value of correlation in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Final SVR Model\n",
    "The final model was trained with the selected features as shown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_index = [0, 3, 6, 7, 10, 12, 13, 14, 15, 16, 18, 19, 24, 25, 35, 37, 38, 39]\n",
    "all_data_selected_features = all_data[:, selected_features_index]\n",
    "selected_features_train = train_features_scaled[:, selected_features_index]\n",
    "selected_features_test = test_features_scaled[:, selected_features_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 840 candidates, totalling 840 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 684 tasks      | elapsed:   20.3s\n",
      "[Parallel(n_jobs=-1)]: Done 840 out of 840 | elapsed:   27.2s finished\n"
     ]
    }
   ],
   "source": [
    "gammas = np.logspace(-6, -1, 6)\n",
    "Cs = np.array([0.5, 1, 2, 4, 8, 10, 15, 20, 50, 100, 200, 375, 500, 1000])\n",
    "epsilons = np.linspace(0.1, 1, 10)\n",
    "param = dict(gamma=gammas, C=Cs, epsilon=epsilons)\n",
    "\n",
    "svr = SVR(kernel='rbf', tol=1)\n",
    "gssvr = GridSearchCV(svr,\n",
    "                     param,\n",
    "                     cv=ps,\n",
    "                     scoring=pearson_scorer,\n",
    "                     n_jobs=-1,\n",
    "                     verbose=1)\n",
    "gssvr = gssvr.fit(all_data_selected_features, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = gssvr.best_params_\n",
    "best_model = SVR(kernel='rbf', tol=1, **best_parameters)\n",
    "train_predictions = best_model.fit(selected_features_train, train_gs).predict(selected_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.4 ms, sys: 22 Âµs, total: 53.5 ms\n",
      "Wall time: 52.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_predictions = best_model.predict(selected_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_correlation = pearsonr(train_predictions, train_gs)[0]\n",
    "test_correlation = pearsonr(test_predictions, test_gs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train pearsonr:  0.8612974649511776\n",
      "Test pearsonr:  0.7456997951303734\n",
      "Best model parameters:\n",
      "\tC: 1.0\n",
      "\tepsilon: 0.4\n",
      "\tgamma: 0.1\n"
     ]
    }
   ],
   "source": [
    "print('Train pearsonr: ', train_correlation)\n",
    "print('Test pearsonr: ', test_correlation)\n",
    "print(\"Best model parameters:\")\n",
    "for k, v in best_parameters.items():\n",
    "    print(f\"\\t{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Conclusions\n",
    "A pearson correlation of `0.746` has been obtained using an SVR. We think that it is a good result given that it is quite close to the 10th participant in the SemEval contest. However, the solution comes at a higher computational cost than traditional methods of semantic similarity. In our tests we saw a pearson correlation of `0.67` between the ground truth and the dice distance of the sentence with no stopwords, lemmatized and in lowercase. This means that all the algorithms that were performed on top of it became a significant overhead in computation time for a relatively small increment in correlation. Also, the synset similarities tend to be quite expensive computationally as well and even though they were very good contributors to the correlation, they are not time efficient at all.\n",
    "\n",
    "However, seing that the inference cost of the model is around `55.1`ms, we can safely compute the algorithms proposed without any kind of concern on computatuinal power availability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# End STS Project"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
