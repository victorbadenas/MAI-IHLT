{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Module Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from nltk.metrics.distance import jaccard_distance\n",
    "from collections.abc import Iterable\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import load_data\n",
    "from dimension.lexical import *\n",
    "from dimension.syntactical import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = load_data('data/')\n",
    "print(\n",
    "    f\"train_data samples: {len(train_data)}, test_data samples: {len(test_data)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Similarity functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(s1, s2):\n",
    "    assert isinstance(s1, Iterable), f\"s1 must be an iterable, not {type(s1)}\"\n",
    "    assert isinstance(s2, Iterable), f\"s2 must be an iterable, not {type(s2)}\"\n",
    "    return 1 - jaccard_distance(set(s1), set(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_similarity(s1, s2):\n",
    "    assert isinstance(s1, Iterable), f\"s1 must be an iterable, not {type(s1)}\"\n",
    "    assert isinstance(s2, Iterable), f\"s2 must be an iterable, not {type(s2)}\"\n",
    "    s1 = set(s1)\n",
    "    s2 = set(s2)\n",
    "    intersection = s1.intersection(s2)\n",
    "    return len(intersection) / min(len(s1), len(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(s1, s2):\n",
    "    assert isinstance(s1, Iterable), f\"s1 must be an iterable, not {type(s1)}\"\n",
    "    assert isinstance(s2, Iterable), f\"s2 must be an iterable, not {type(s2)}\"\n",
    "    s1 = set(s1)\n",
    "    s2 = set(s2)\n",
    "    intersection = s1.intersection(s2)\n",
    "    return len(intersection) / ((len(s1) * len(s2))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_similarity(s1, s2):\n",
    "    assert isinstance(s1, Iterable), f\"s1 must be an iterable, not {type(s1)}\"\n",
    "    assert isinstance(s2, Iterable), f\"s2 must be an iterable, not {type(s2)}\"\n",
    "    s1 = set(s1)\n",
    "    s2 = set(s2)\n",
    "    intersection = s1.intersection(s2)\n",
    "    return 2 * len(intersection) / (len(s1) + len(s2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Feature loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature vector builder for dataframe of sentence pairs\n",
    "\n",
    "Declaration of the function responsible for the iteration over the dataframe containing the sentence pairs (other columns shall be unused). Requires the sentences columns' to be named `\"S1\"` and `\"S2\"`.\n",
    "\n",
    "Returns a numpy array of shape `(n_sentence_pairs, n_features)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(df: pd.DataFrame):\n",
    "    assert \"S1\" in df.columns, \"S1 not in dataframe\"\n",
    "    assert \"S2\" in df.columns, \"S2 not in dataframe\"\n",
    "\n",
    "    features = [None] * len(df)   #preallocated for memory efficiency\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        sentence1, sentence2 = row['S1'], row['S2']\n",
    "\n",
    "        # Get all words\n",
    "        tokenized_1, tokenized_2 = get_tokenized_sentences(\n",
    "            sentence1, sentence2, return_unique_words=False)\n",
    "        tokenized_lc_1, tokenized_lc_2 = get_tokenized_sentences_lowercase(\n",
    "            tokenized_1, tokenized_2, return_unique_words=False)\n",
    "\n",
    "        # Get words without stopwords\n",
    "        no_stopwords_1, no_stopwords_2 = filter_stopwords(\n",
    "            tokenized_1, tokenized_2, return_unique_words=False)\n",
    "        no_stopwords_lc_1, no_stopwords_lc_2 = filter_stopwords(\n",
    "            tokenized_lc_1, tokenized_lc_2, return_unique_words=False)\n",
    "\n",
    "        # Lemmas\n",
    "        lemmatized_1, lemmatized_2 = get_lemmas(tokenized_1,\n",
    "                                                tokenized_2,\n",
    "                                                return_unique_words=False)\n",
    "        lemmatized_lc_1, lemmatized_lc_2 = get_lemmas(\n",
    "            tokenized_lc_1, tokenized_lc_2, return_unique_words=False)\n",
    "\n",
    "        # Name entities\n",
    "        sentence_ne_1, sentence_ne_2 = get_named_entities(\n",
    "            tokenized_1, tokenized_2)\n",
    "        \n",
    "        #lemmas cleaned from stopwords\n",
    "        stopwords_and_lemmas1, stopwords_and_lemmas2 = get_lemmas(\n",
    "            no_stopwords_1, no_stopwords_2, return_unique_words=False)\n",
    "\n",
    "        stopwords_and_lemmas_lc_1, stopwords_and_lemmas_lc_2 = get_lemmas(\n",
    "            no_stopwords_lc_1, no_stopwords_lc_2, return_unique_words=False)\n",
    "        \n",
    "        # Name entities without stopwords in lowercase\n",
    "        ne_no_stopwords_1, ne_no_stopwords_2 = filter_stopwords(\n",
    "            sentence_ne_1, sentence_ne_2, return_unique_words=False, filter_and_return_in_lowercase=True)\n",
    "        \n",
    "        # Name entities without stopwords in lowercase and lemmas\n",
    "        ne_no_stopwords_lemmas_1, ne_no_stopwords_lemmas_2 = get_lemmas( ne_no_stopwords_1, ne_no_stopwords_2, \n",
    "                                                                        return_unique_words=False)\n",
    "\n",
    "        # Bigrams\n",
    "        bigrams_1, bigrams_2 = get_ngrams(no_stopwords_1, no_stopwords_2, n=2)\n",
    "        trigrams_1, trigrams_2 = get_ngrams(no_stopwords_1, no_stopwords_2, n=3)\n",
    "        \n",
    "        # Bigrams trigrams with sentence tokenizer \n",
    "        bigrams_sent_1, bigrams_sent_2 = get_ngrams_with_sent_tokenize(sentence1, sentence2, n=2)\n",
    "        trigrams_sent_1, trigrams_sent_2 = get_ngrams_with_sent_tokenize(sentence1, sentence2, n=3)\n",
    "        \n",
    "        # Lesk\n",
    "        lesk_1, lesk_2 = get_lesk_sentences(tokenized_1, tokenized_2)\n",
    "\n",
    "        # Stemmer\n",
    "        stemmed_1, stemmed_2 = get_stemmed_sentences(sentence1, sentence2)\n",
    "        \n",
    "        # ALL Features\n",
    "        features[index] = [\n",
    "            jaccard_similarity(tokenized_1, tokenized_2),\n",
    "            jaccard_similarity(tokenized_lc_1, tokenized_lc_2),\n",
    "            jaccard_similarity(no_stopwords_1, no_stopwords_2),\n",
    "            jaccard_similarity(no_stopwords_lc_1, no_stopwords_lc_2),\n",
    "            jaccard_similarity(lemmatized_1, lemmatized_2),\n",
    "            jaccard_similarity(lemmatized_lc_1, lemmatized_lc_2),\n",
    "            jaccard_similarity(sentence_ne_1, sentence_ne_2),\n",
    "            jaccard_similarity(stopwords_and_lemmas1, stopwords_and_lemmas2),\n",
    "            jaccard_similarity(stopwords_and_lemmas_lc_1, stopwords_and_lemmas_lc_2),\n",
    "            jaccard_similarity(bigrams_1, bigrams_2),\n",
    "            jaccard_similarity(trigrams_1, trigrams_2),\n",
    "            jaccard_similarity(bigrams_sent_1, bigrams_sent_2),\n",
    "            jaccard_similarity(trigrams_sent_1, trigrams_sent_2),\n",
    "            jaccard_similarity(lesk_1, lesk_2),\n",
    "            jaccard_similarity(stemmed_1, stemmed_2),\n",
    "            \n",
    "            dice_similarity(tokenized_1, tokenized_2),\n",
    "            dice_similarity(tokenized_lc_1, tokenized_lc_2),\n",
    "            dice_similarity(no_stopwords_1, no_stopwords_2),\n",
    "            dice_similarity(no_stopwords_lc_1, no_stopwords_lc_2),\n",
    "            dice_similarity(lemmatized_1, lemmatized_2),\n",
    "            dice_similarity(lemmatized_lc_1, lemmatized_lc_2),\n",
    "            dice_similarity(sentence_ne_1, sentence_ne_2),\n",
    "            dice_similarity(stopwords_and_lemmas1, stopwords_and_lemmas2),\n",
    "            dice_similarity(stopwords_and_lemmas_lc_1, stopwords_and_lemmas_lc_2),\n",
    "            dice_similarity(bigrams_1, bigrams_2),\n",
    "            dice_similarity(trigrams_1, trigrams_2),\n",
    "            dice_similarity(bigrams_sent_1, bigrams_sent_2),\n",
    "            dice_similarity(trigrams_sent_1, trigrams_sent_2),\n",
    "            dice_similarity(lesk_1, lesk_2),\n",
    "            dice_similarity(stemmed_1, stemmed_2)\n",
    "        ]\n",
    "        # BEST Features selection \n",
    "        \"\"\"features[index] = [\n",
    "        jaccard_similarity(tokenized_1, tokenized_2),\n",
    "        jaccard_similarity(no_stopwords_1, no_stopwords_2),\n",
    "        jaccard_similarity(lemmatized_1, lemmatized_2),\n",
    "        jaccard_similarity(bigrams_1, bigrams_2),\n",
    "        jaccard_similarity(trigrams_1, trigrams_2),\n",
    "        dice_similarity(tokenized_1, tokenized_2),\n",
    "        dice_similarity(no_stopwords_1, no_stopwords_2),\n",
    "        dice_similarity(no_stopwords_lc_1, no_stopwords_lc_2),\n",
    "        dice_similarity(sentence_ne_1, sentence_ne_2),\n",
    "        dice_similarity(bigrams_1, bigrams_2),\n",
    "        dice_similarity(trigrams_1, trigrams_2),\n",
    "        dice_similarity(stopwords_and_lemmas_lc_1, stopwords_and_lemmas_lc_2),\n",
    "        dice_similarity(lesk_1, lesk_2)\n",
    "        ]\"\"\"\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST cell don't delete it =D\n",
    "\n",
    "first = \"My Bonnie White lies over the ocean, in Picadilli Circus at 3:00pm.\"\n",
    "second = \"My Bonnie lied over the sea! Over the sea...\"\n",
    "\n",
    "tokenized_1, tokenized_2 = get_tokenized_sentences(first,\n",
    "                                                   second,\n",
    "                                                   return_unique_words=False)\n",
    "no_stopwords_1, no_stopwords_2 = filter_stopwords(tokenized_1, tokenized_2, return_unique_words=False)\n",
    "sentence_ne_1, sentence_ne_2 = get_named_entities(no_stopwords_1, no_stopwords_2)\n",
    "\n",
    "print(tokenized_1)\n",
    "print(tokenized_2)\n",
    "print(sentence_ne_1)\n",
    "print(sentence_ne_2)\n",
    "#TEST cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train features extraction\n",
    "\n",
    "Using the function declared above, the features are extracted from the `train_data` dataframe. Also the Gold Standard is extracted from its column in the dataframe. The shapes for both numpy vectors are displayed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = get_features(train_data)\n",
    "train_gs = train_data['Gs'].to_numpy()\n",
    "print(f\"train_features.shape: {train_features.shape}\")\n",
    "print(f\"train_gs.shape: {train_gs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test features extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_features = get_features(test_data)\n",
    "test_gs = test_data['Gs'].to_numpy()\n",
    "print(f\"train_features.shape: {test_features.shape}\")\n",
    "print(f\"train_gs.shape: {test_gs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Feature scaling\n",
    "\n",
    "features are scaled using sklearns StandardScaler, where the mean is substracted for each feature and it's divided by the variance of the feature to obtain a unified feature space with zero mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_features_scaled = scaler.fit_transform(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_features_scaled = scaler.transform(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predefined Fold for GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import PredefinedSplit\n",
    "all_data = np.concatenate([train_features_scaled, test_features_scaled])\n",
    "all_labels = np.concatenate([train_gs, test_gs])\n",
    "test_fold = np.array([-1]*train_features_scaled.shape[0] + [0]*test_features_scaled.shape[0])\n",
    "print(all_data.shape, test_fold.shape)\n",
    "ps = PredefinedSplit(test_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing if the predefined split is correct\n",
    "train_idx, test_idx = list(ps.split())[0]\n",
    "print(train_idx.shape, test_idx.shape)\n",
    "print(train_features_scaled.shape, test_features_scaled.shape)\n",
    "\n",
    "assert np.all(all_data[train_idx] == train_features_scaled), \"incorrect split\"\n",
    "assert np.all(all_data[test_idx] == test_features_scaled), \"incorrect split\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pearson_scorer = make_scorer(lambda y, y_hat: pearsonr(y, y_hat)[0])\n",
    "\n",
    "gammas = np.logspace(-6, -1, 6)\n",
    "Cs = np.array([0.5, 1, 2, 4, 8, 10, 15, 20, 50, 100, 200, 375, 500, 1000])\n",
    "epsilons = np.linspace(0.1, 1, 10)\n",
    "svm_param = dict(gamma=gammas, C=Cs, epsilon=epsilons)\n",
    "\n",
    "svr = SVR(kernel='rbf', tol=1)\n",
    "gssvr = GridSearchCV(svr,\n",
    "                     svm_param,\n",
    "                     cv=ps,\n",
    "                     scoring=pearson_scorer,\n",
    "                     n_jobs=-1,\n",
    "                     verbose=1)\n",
    "gssvr = gssvr.fit(all_data, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_best_params = gssvr.best_params_\n",
    "best_svr = SVR(kernel='rbf', tol=1, **svr_best_params)\n",
    "best_svr.fit(train_features_scaled, train_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_svm_predictions = best_svr.predict(train_features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_svm_predictions = best_svr.predict(test_features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_svm_correlation = pearsonr(train_svm_predictions, train_gs)[0]\n",
    "test_svm_correlation = pearsonr(test_svm_predictions, test_gs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Train pearsonr:', train_svm_correlation)\n",
    "print(\"Test pearsonr: \", test_svm_correlation)\n",
    "print('The best value of gamma:', gssvr.best_estimator_.gamma)\n",
    "print('The best value of C:', gssvr.best_estimator_.C)\n",
    "print('The best value of epsilon:', gssvr.best_estimator_.epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "alphas = np.logspace(-6, -1, 6)\n",
    "hidden_layer_sizes = [(i,) for i in range(5, 305, 10)]\n",
    "mlp_param = dict(alpha=alphas, hidden_layer_sizes=hidden_layer_sizes)\n",
    "\n",
    "mlpr = MLPRegressor(max_iter=1000, random_state=1)\n",
    "mgsmlp = GridSearchCV(mlpr,\n",
    "                      mlp_param,\n",
    "                      cv=ps,\n",
    "                      scoring=pearson_scorer,\n",
    "                      n_jobs=-1,\n",
    "                      verbose=1)\n",
    "mgsmlp = mgsmlp.fit(all_data, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_best_params = mgsmlp.best_params_\n",
    "best_mlp = MLPRegressor(max_iter=1000, random_state=1, **mlp_best_params)\n",
    "best_mlp.fit(train_features_scaled, train_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mlp_predictions = best_mlp.predict(train_features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_mlp_predictions = best_mlp.predict(test_features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mlp_correlation = pearsonr(train_mlp_predictions, train_gs)[0]\n",
    "test_mlp_correlation = pearsonr(test_mlp_predictions, test_gs)[0]\n",
    "print('Train pearsonr:', train_mlp_correlation)\n",
    "print(\"Test pearsonr: \", test_mlp_correlation)\n",
    "print('The best value of alpha:', mgsmlp.best_estimator_.alpha)\n",
    "print('The best value of hidden_layer_sizes:', mgsmlp.best_estimator_.hidden_layer_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "weights = ['uniform', 'distance']\n",
    "nn = list(range(10, 101, 10))\n",
    "algorithms = ['ball_tree', 'kd_tree', 'brute']\n",
    "leaf_sizes = list(range(1, 51, 10))\n",
    "pvalues = list(range(1, 6))\n",
    "\n",
    "nn_params = dict(n_neighbors=nn, weights=weights, p=pvalues, leaf_size=leaf_sizes, algorithm=algorithms)\n",
    "\n",
    "nnr = KNeighborsRegressor()\n",
    "nnrmlp = GridSearchCV(nnr,\n",
    "                      nn_params,\n",
    "                      cv=ps,\n",
    "                      scoring=pearson_scorer,\n",
    "                      n_jobs=-1,\n",
    "                      verbose=1)\n",
    "\n",
    "nnrmlp = nnrmlp.fit(all_data, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnr_best_params = nnrmlp.best_params_\n",
    "best_nnr = KNeighborsRegressor(**nnr_best_params)\n",
    "best_nnr.fit(train_features_scaled, train_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nnr_predictions = best_nnr.predict(train_features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_nnr_predictions = best_nnr.predict(test_features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_nnr_correlation = pearsonr(train_nnr_predictions, train_gs)[0]\n",
    "test_nnr_correlation = pearsonr(test_nnr_predictions, test_gs)[0]\n",
    "print('Train pearsonr: ', train_nnr_correlation)\n",
    "print(\"Test pearsonr: \", test_nnr_correlation)\n",
    "print('The best value of n_neighbors:', nnrmlp.best_estimator_.n_neighbors)\n",
    "print('The best value of weights:', nnrmlp.best_estimator_.weights)\n",
    "print('The best value of p:', nnrmlp.best_estimator_.p)\n",
    "print('The best value of leaf_size:', nnrmlp.best_estimator_.leaf_size)\n",
    "print('The best value of algorithm:', nnrmlp.best_estimator_.algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottleneck Layer MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "bottleneck_length = range(3, test_features.shape[-1])\n",
    "hidden_layer_length = range(4, 100, 20)\n",
    "alphas_lin = np.linspace(0, 1, 6)\n",
    "hidden_layer_sizes = list(product(bottleneck_length, hidden_layer_length))\n",
    "\n",
    "param = dict(hidden_layer_sizes=hidden_layer_sizes, alpha=alphas_lin)\n",
    "\n",
    "bmlp = MLPRegressor(max_iter=500, random_state=1)\n",
    "gsbmlp = GridSearchCV(bmlp,\n",
    "                          param,\n",
    "                          cv=ps,\n",
    "                          scoring=pearson_scorer,\n",
    "                          n_jobs=-1,\n",
    "                          verbose=1)\n",
    "gsbmlp = gsbmlp.fit(all_data, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_mlp_best_params = gsbmlp.best_params_\n",
    "best_bt_mlp = MLPRegressor(max_iter=500, random_state=1, **bt_mlp_best_params)\n",
    "best_bt_mlp.fit(train_features_scaled, train_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bt_mlp_predictions = best_bt_mlp.predict(train_features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_bt_mlp_predictions = best_bt_mlp.predict(test_features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bt_mlp_correlation = pearsonr(train_bt_mlp_predictions, train_gs)[0]\n",
    "test_bt_mlp_correlation = pearsonr(test_bt_mlp_predictions, test_gs)[0]\n",
    "print('Train pearsonr: ', train_bt_mlp_correlation)\n",
    "print('Test pearsonr: ', test_bt_mlp_correlation)\n",
    "print('The best value of alpha:', gsbmlp.best_estimator_.alpha)\n",
    "print('The best value of hidden_layer_sizes:', gsbmlp.best_estimator_.hidden_layer_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = {\n",
    "    \"SVR\": {\"train\": train_svm_correlation,\"test\": test_svm_correlation},\n",
    "    \"MLP\": {\"train\": train_mlp_correlation,\"test\": test_mlp_correlation},\n",
    "    \"NNR\": {\"train\": train_nnr_correlation,\"test\": test_nnr_correlation},\n",
    "    \"BtBLP\": {\"train\": train_bt_mlp_correlation,\"test\": test_bt_mlp_correlation},\n",
    "}\n",
    "print(pd.DataFrame.from_dict(correlations, orient=\"index\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('IHLT3.7': conda)",
   "language": "python",
   "name": "python37964bitihlt37conda7204be5f521f4785b21789281fd931be"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
